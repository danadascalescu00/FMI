{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danadascalescu00/FMI/blob/master/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUqYhT2cKQkC"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCgOwIzMKQkH"
      },
      "source": [
        "#### Install NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iSBno5GKQkI",
        "outputId": "d612adc3-02f2-4279-c8fa-49a1cc037fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SnloOsAKQkL"
      },
      "source": [
        "#### Download models or corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpdyblmdKQkL",
        "outputId": "465c8b05-ed1f-4683-e317-c55b29513ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 982, in _interactive_download\n",
            "    DownloaderGUI(self).mainloop()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 1226, in __init__\n",
            "    top = self.top = Tk()\n",
            "  File \"/usr/lib/python3.7/tkinter/__init__.py\", line 2023, in __init__\n",
            "    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)\n",
            "_tkinter.TclError: no display name and no $DISPLAY environment variable\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 2278, in <module>\n",
            "    halt_on_error=options.halt_on_error)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 661, in download\n",
            "    self._interactive_download()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 984, in _interactive_download\n",
            "    DownloaderShell(self).run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 1006, in run\n",
            "    user_input = input('Downloader> ').strip()\n",
            "EOFError: EOF when reading a line\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python -m nltk.downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNIjJv6gKQkM"
      },
      "source": [
        "#### Import and use"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjqqSqqQPLkm",
        "outputId": "1d4571c7-22ac-4c05-94a4-f7303d6de040"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> u\n",
            "\n",
            "Nothing to update.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> l\n",
            "\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6w4uDe3KQkM",
        "outputId": "b809bbb0-6293-47d2-f795-58adb2117d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Z_YbkT-6KQkN"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "b7OK-ijPKQkO"
      },
      "outputs": [],
      "source": [
        "tweet = \"RT @lOR42wsOEFcv3f: I fall too fast, crash too hard, forgive too easily and care too much... :( #amiright\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-47dxdbVKQkO"
      },
      "outputs": [],
      "source": [
        "query = 'fast'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmulMqX2KQkP",
        "outputId": "6a893172-deba-47ed-a8c3-7e472a010de6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "tweet.find(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LI-Au23KQkQ"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBnNrE7PKQkQ",
        "outputId": "0c544ce1-8af2-4c75-c7dd-cdc5ac41d021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@lOR42wsOEFcv3f:',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast,',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard,',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much...',\n",
              " ':(',\n",
              " '#amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tweet.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06BsrYpNKQkQ",
        "outputId": "700870e7-8002-481b-b06b-9889cda8c019"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "[query in tweet.split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WWnJGlk7KQkR",
        "outputId": "ba6b253b-3166-4aa1-b81b-5b37a0d58086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'lOR42wsOEFcv3f',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':',\n",
              " '(',\n",
              " '#',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "nltk.word_tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnei4puZKQkR",
        "outputId": "60b41298-e974-433c-8d66-33f6334a993c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "[query in nltk.word_tokenize(tweet)]\n",
        "# query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Zty9U7KQkS",
        "outputId": "408d5f93-7d76-4963-f5f1-13cda742097f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'lOR42wsOEFcv3f',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':',\n",
              " '(',\n",
              " '#',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "nltk.word_tokenize(tweet, language='spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "M6h-Ya7uKQkS"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "custom_tokenizer = RegexpTokenizer('[a-zA-Z0-9]+', discard_empty=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD1E3-ROKQkT",
        "outputId": "bbdd02a9-ec1c-4d4f-b867-130ab21a0aee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " 'lOR42wsOEFcv3f',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "custom_tokenizer.tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_GzYduc-KQkT"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_tokenizer.tokenize(\"helloooooooo there\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8v7OerdT7tx",
        "outputId": "b6481290-2fcb-450a-a08e-374d618f0c60"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hellooo', 'there']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WduYN2feKQkU",
        "outputId": "84f50c5c-8ef9-4d1a-8431-ee23f49af896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(',\n",
              " '#amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "tweet_tokenizer.tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9JMQyi6KQkU",
        "outputId": "e321d52c-372e-49f3-ec45-a86cfad0dfa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too_fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(',\n",
              " '#amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "mwe = MWETokenizer()\n",
        "mwe.add_mwe(('too', 'fast'))\n",
        "mwe.tokenize(tweet_tokenizer.tokenize(tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FRZUDvy4KQkU"
      },
      "outputs": [],
      "source": [
        "mwe.add_mwe((('too', 'fast'), ('too', 'hard')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axdDoJtBKQkV",
        "outputId": "66985b0f-dbaa-4ede-f334-7dd37b0e7d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "query = 'fast'\n",
        "query in mwe.tokenize(tweet_tokenizer.tokenize(tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DlfVJ3hKQkV"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "JGQXxdJmKQkV",
        "outputId": "ce480cb1-6003-46c2-851c-f257ba7ea43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rt @lor42wsoefcv3f: i fall too fast, crash too hard, forgive too easily and care too much... :( #amiright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tweet.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "weo0WMfbKQkW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def normalize_tokens(tokenized_text):\n",
        "    # Lowercase\n",
        "    tokens = [t.lower() for t in tokenized_text]\n",
        "    # Remove hashtags\n",
        "    tokens = [t for t in tokens if not t.startswith('#')]\n",
        "    # Remove punctuation\n",
        "    tokens = [t for t in tokens if t not in string.punctuation]\n",
        "    # Keep only letters\n",
        "#     tokens = [t for t in tokens if re.match('^[a-z]+$', t)]\n",
        "    # Normalize characters\n",
        "    tokens = [re.sub('á', 'a', t) for t in tokens]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKvI2uOlKQkW",
        "outputId": "8aba9b5b-3d51-46d2-d38f-75076faba81d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muy', 'rapido']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "spanish_query = 'muy rápido'\n",
        "normalize_tokens(tweet_tokenizer.tokenize(spanish_query))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXWM8zsQX7lU",
        "outputId": "ba68d724-832a-4e68-babe-63744b967490"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "3Ag6Rt1cKQkW",
        "outputId": "e370d244-0ea7-4743-ee13-2022e7746f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'muy rapido'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import unidecode\n",
        "unidecode.unidecode(spanish_query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unidecode.unidecode('Războiul de independență al Greciei, cunoscut și ca Revoluția greacă (în limbile greacă: Ελληνική Επανάσταση Elliniki Epanastasi; turcă otomană: يونان عصياني Yunan İsyanı) a fost declanșat de revoluționarii greci și s-a desfășurat între anii 1821 – 1829. Revoluționarii au beneficiat într-o etapă mai târzie a războiului de sprijinul unor puteri europene, iar Imperiul Otoman a fost sprijinit de vasalii săi, Egiptul și într-o oarecare măsură Vilaietul Tunisia.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "FPC2DXGzY81o",
        "outputId": "f7ed5608-b734-4256-84fe-f69dd41d34dd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Razboiul de independenta al Greciei, cunoscut si ca Revolutia greaca (in limbile greaca: Ellenike Epanastase Elliniki Epanastasi; turca otomana: ywnn `Syny Yunan Isyani) a fost declansat de revolutionarii greci si s-a desfasurat intre anii 1821 - 1829. Revolutionarii au beneficiat intr-o etapa mai tarzie a razboiului de sprijinul unor puteri europene, iar Imperiul Otoman a fost sprijinit de vasalii sai, Egiptul si intr-o oarecare masura Vilaietul Tunisia.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQOMdK7NKQkX",
        "outputId": "5494b2dc-bd7a-4afb-a562-d64ef8baa243"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "normalize_tokens(tweet_tokenizer.tokenize(tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9QwbDTHKQkX"
      },
      "source": [
        "#### Uniform normalization principle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLpo_bk0KQkX",
        "outputId": "a9f78fc9-f960-45ee-f446-06eb0ec1039d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['too', 'fast', 'too', 'furious']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "query = 'TOO fast TOO furious'\n",
        "tokenized_query = tweet_tokenizer.tokenize(query)\n",
        "normalized_query = normalize_tokens(tokenized_query)\n",
        "# normalized_query = tokenized_query\n",
        "normalized_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysX7lcZpKQkY",
        "outputId": "610a7469-8943-47e4-83c5-65c83c26c07c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "# normalized_tweet = normalize_tokens(tweet.split())\n",
        "normalized_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hzeavdHKQkb",
        "outputId": "a74d58e4-2fee-45d8-9ddd-46098538a452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fast', 'too'}\n",
            "2 common word(s)\n"
          ]
        }
      ],
      "source": [
        "common_words = set(normalized_query).intersection(normalized_tweet)\n",
        "print(common_words)\n",
        "print(len(common_words), \"common word(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VjacKJLKQkb"
      },
      "source": [
        "#### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN10dqroKQkb",
        "outputId": "76c08c1c-a9ff-480e-bffe-3452a40f3c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkJV-s0JKQkc",
        "outputId": "ad6428b4-31db-4cc3-dcb2-e1dab860323e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('romanian')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6pCHILXahD9",
        "outputId": "c41917c9-3dff-4f65-ed58-4c1d8555ca33"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'abia',\n",
              " 'acea',\n",
              " 'aceasta',\n",
              " 'această',\n",
              " 'aceea',\n",
              " 'aceeasi',\n",
              " 'acei',\n",
              " 'aceia',\n",
              " 'acel',\n",
              " 'acela',\n",
              " 'acelasi',\n",
              " 'acele',\n",
              " 'acelea',\n",
              " 'acest',\n",
              " 'acesta',\n",
              " 'aceste',\n",
              " 'acestea',\n",
              " 'acestei',\n",
              " 'acestia',\n",
              " 'acestui',\n",
              " 'aceşti',\n",
              " 'aceştia',\n",
              " 'adica',\n",
              " 'ai',\n",
              " 'aia',\n",
              " 'aibă',\n",
              " 'aici',\n",
              " 'al',\n",
              " 'ala',\n",
              " 'ale',\n",
              " 'alea',\n",
              " 'alt',\n",
              " 'alta',\n",
              " 'altceva',\n",
              " 'altcineva',\n",
              " 'alte',\n",
              " 'altfel',\n",
              " 'alti',\n",
              " 'altii',\n",
              " 'altul',\n",
              " 'am',\n",
              " 'anume',\n",
              " 'apoi',\n",
              " 'ar',\n",
              " 'are',\n",
              " 'as',\n",
              " 'asa',\n",
              " 'asta',\n",
              " 'astea',\n",
              " 'astfel',\n",
              " 'asupra',\n",
              " 'atare',\n",
              " 'atat',\n",
              " 'atata',\n",
              " 'atatea',\n",
              " 'atatia',\n",
              " 'ati',\n",
              " 'atit',\n",
              " 'atita',\n",
              " 'atitea',\n",
              " 'atitia',\n",
              " 'atunci',\n",
              " 'au',\n",
              " 'avea',\n",
              " 'avem',\n",
              " 'aveţi',\n",
              " 'avut',\n",
              " 'aş',\n",
              " 'aţi',\n",
              " 'ba',\n",
              " 'ca',\n",
              " 'cam',\n",
              " 'cand',\n",
              " 'care',\n",
              " 'careia',\n",
              " 'carora',\n",
              " 'caruia',\n",
              " 'cat',\n",
              " 'catre',\n",
              " 'ce',\n",
              " 'cea',\n",
              " 'ceea',\n",
              " 'cei',\n",
              " 'ceilalti',\n",
              " 'cel',\n",
              " 'cele',\n",
              " 'celor',\n",
              " 'ceva',\n",
              " 'chiar',\n",
              " 'ci',\n",
              " 'cind',\n",
              " 'cine',\n",
              " 'cineva',\n",
              " 'cit',\n",
              " 'cita',\n",
              " 'cite',\n",
              " 'citeva',\n",
              " 'citi',\n",
              " 'citiva',\n",
              " 'cu',\n",
              " 'cui',\n",
              " 'cum',\n",
              " 'cumva',\n",
              " 'cât',\n",
              " 'câte',\n",
              " 'câtva',\n",
              " 'câţi',\n",
              " 'cînd',\n",
              " 'cît',\n",
              " 'cîte',\n",
              " 'cîtva',\n",
              " 'cîţi',\n",
              " 'că',\n",
              " 'căci',\n",
              " 'cărei',\n",
              " 'căror',\n",
              " 'cărui',\n",
              " 'către',\n",
              " 'da',\n",
              " 'daca',\n",
              " 'dacă',\n",
              " 'dar',\n",
              " 'dat',\n",
              " 'dată',\n",
              " 'dau',\n",
              " 'de',\n",
              " 'deasupra',\n",
              " 'deci',\n",
              " 'decit',\n",
              " 'deja',\n",
              " 'desi',\n",
              " 'despre',\n",
              " 'deşi',\n",
              " 'din',\n",
              " 'dintr',\n",
              " 'dintr-',\n",
              " 'dintre',\n",
              " 'doar',\n",
              " 'doi',\n",
              " 'doilea',\n",
              " 'două',\n",
              " 'drept',\n",
              " 'dupa',\n",
              " 'după',\n",
              " 'dă',\n",
              " 'e',\n",
              " 'ea',\n",
              " 'ei',\n",
              " 'el',\n",
              " 'ele',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'este',\n",
              " 'eu',\n",
              " 'eşti',\n",
              " 'face',\n",
              " 'fara',\n",
              " 'fata',\n",
              " 'fel',\n",
              " 'fi',\n",
              " 'fie',\n",
              " 'fiecare',\n",
              " 'fii',\n",
              " 'fim',\n",
              " 'fiu',\n",
              " 'fiţi',\n",
              " 'foarte',\n",
              " 'fost',\n",
              " 'fără',\n",
              " 'i',\n",
              " 'ia',\n",
              " 'iar',\n",
              " 'ii',\n",
              " 'il',\n",
              " 'imi',\n",
              " 'in',\n",
              " 'inainte',\n",
              " 'inapoi',\n",
              " 'inca',\n",
              " 'incit',\n",
              " 'insa',\n",
              " 'intr',\n",
              " 'intre',\n",
              " 'isi',\n",
              " 'iti',\n",
              " 'la',\n",
              " 'le',\n",
              " 'li',\n",
              " 'lor',\n",
              " 'lui',\n",
              " 'lângă',\n",
              " 'lîngă',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'mai',\n",
              " 'mea',\n",
              " 'mei',\n",
              " 'mele',\n",
              " 'mereu',\n",
              " 'meu',\n",
              " 'mi',\n",
              " 'mie',\n",
              " 'mine',\n",
              " 'mod',\n",
              " 'mult',\n",
              " 'multa',\n",
              " 'multe',\n",
              " 'multi',\n",
              " 'multă',\n",
              " 'mulţi',\n",
              " 'mâine',\n",
              " 'mîine',\n",
              " 'mă',\n",
              " 'ne',\n",
              " 'ni',\n",
              " 'nici',\n",
              " 'nimeni',\n",
              " 'nimic',\n",
              " 'niste',\n",
              " 'nişte',\n",
              " 'noastre',\n",
              " 'noastră',\n",
              " 'noi',\n",
              " 'nostri',\n",
              " 'nostru',\n",
              " 'nou',\n",
              " 'noua',\n",
              " 'nouă',\n",
              " 'noştri',\n",
              " 'nu',\n",
              " 'numai',\n",
              " 'o',\n",
              " 'or',\n",
              " 'ori',\n",
              " 'oricare',\n",
              " 'orice',\n",
              " 'oricine',\n",
              " 'oricum',\n",
              " 'oricând',\n",
              " 'oricât',\n",
              " 'oricînd',\n",
              " 'oricît',\n",
              " 'oriunde',\n",
              " 'pai',\n",
              " 'parca',\n",
              " 'patra',\n",
              " 'patru',\n",
              " 'pe',\n",
              " 'pentru',\n",
              " 'peste',\n",
              " 'pic',\n",
              " 'pina',\n",
              " 'poate',\n",
              " 'pot',\n",
              " 'prea',\n",
              " 'prima',\n",
              " 'primul',\n",
              " 'prin',\n",
              " 'printr-',\n",
              " 'putini',\n",
              " 'puţin',\n",
              " 'puţina',\n",
              " 'puţină',\n",
              " 'până',\n",
              " 'pînă',\n",
              " 'sa',\n",
              " 'sa-mi',\n",
              " 'sa-ti',\n",
              " 'sai',\n",
              " 'sale',\n",
              " 'sau',\n",
              " 'se',\n",
              " 'si',\n",
              " 'sint',\n",
              " 'sintem',\n",
              " 'spate',\n",
              " 'spre',\n",
              " 'sub',\n",
              " 'sunt',\n",
              " 'suntem',\n",
              " 'sunteţi',\n",
              " 'sus',\n",
              " 'să',\n",
              " 'săi',\n",
              " 'său',\n",
              " 't',\n",
              " 'ta',\n",
              " 'tale',\n",
              " 'te',\n",
              " 'ti',\n",
              " 'tine',\n",
              " 'toata',\n",
              " 'toate',\n",
              " 'toată',\n",
              " 'tocmai',\n",
              " 'tot',\n",
              " 'toti',\n",
              " 'totul',\n",
              " 'totusi',\n",
              " 'totuşi',\n",
              " 'toţi',\n",
              " 'trei',\n",
              " 'treia',\n",
              " 'treilea',\n",
              " 'tu',\n",
              " 'tuturor',\n",
              " 'tăi',\n",
              " 'tău',\n",
              " 'u',\n",
              " 'ul',\n",
              " 'ului',\n",
              " 'un',\n",
              " 'una',\n",
              " 'unde',\n",
              " 'undeva',\n",
              " 'unei',\n",
              " 'uneia',\n",
              " 'unele',\n",
              " 'uneori',\n",
              " 'unii',\n",
              " 'unor',\n",
              " 'unora',\n",
              " 'unu',\n",
              " 'unui',\n",
              " 'unuia',\n",
              " 'unul',\n",
              " 'v',\n",
              " 'va',\n",
              " 'vi',\n",
              " 'voastre',\n",
              " 'voastră',\n",
              " 'voi',\n",
              " 'vom',\n",
              " 'vor',\n",
              " 'vostru',\n",
              " 'vouă',\n",
              " 'voştri',\n",
              " 'vreo',\n",
              " 'vreun',\n",
              " 'vă',\n",
              " 'zi',\n",
              " 'zice',\n",
              " 'îi',\n",
              " 'îl',\n",
              " 'îmi',\n",
              " 'în',\n",
              " 'îţi',\n",
              " 'ăla',\n",
              " 'ălea',\n",
              " 'ăsta',\n",
              " 'ăstea',\n",
              " 'ăştia',\n",
              " 'şi',\n",
              " 'ţi',\n",
              " 'ţie']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "gcp5ZsEOKQkc"
      },
      "outputs": [],
      "source": [
        "blacklist_words = stopwords.words('english') + ['rt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPD44QeFKQkc",
        "outputId": "2285c3c5-801d-4191-fd3a-475ed18bc302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fast', 'crash', 'hard', 'forgive', 'easily', 'care', 'much', '...', ':(']\n"
          ]
        }
      ],
      "source": [
        "cleaned_tweet = [t for t in normalized_tweet if t not in blacklist_words]\n",
        "print(cleaned_tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAc1l5MNKQkc"
      },
      "source": [
        "#### Stemming / Lemmatization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "ISf4nEUwKQkd"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhbmKAFvKQkd",
        "outputId": "c33b0ee1-6d0a-4f4f-e3fc-e67b5b4dc5e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fall',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'hard',\n",
              " 'forgiv',\n",
              " 'easili',\n",
              " 'care',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "[stemmer.stem(t) for t in cleaned_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yw8205ZKQkd",
        "outputId": "393c3c20-e2f1-4c95-99b2-9a865cf73629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fall',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'hard',\n",
              " 'forgiv',\n",
              " 'easili',\n",
              " 'care',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "[stemmer.stem(t) for t in cleaned_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "[stemmer.stem(t) for t in cleaned_tweet]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEhIUMJqcDbN",
        "outputId": "5352c781-522a-44d1-cf56-161b90bf6e08"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fal', 'fast', 'crash', 'hard', 'forg', 'easy', 'car', 'much', '...', ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfrgHw9oKQke",
        "outputId": "db33d70f-52d2-43a5-8c64-1b2940059123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fall',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'easily',\n",
              " 'care',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "[lemmatizer.lemmatize(t) for t in cleaned_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC85xkdqZ4LG",
        "outputId": "499d0041-53dd-4966-f5a0-ce4cd9d13654"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "3yjnpv_wKQke",
        "outputId": "e4511672-ec7a-485a-e3f5-11ff1451e1e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fall', 'NN'), ('fast', 'RB'), ('crash', 'JJ'), ('hard', 'JJ'), ('forgive', 'NN'), ('easily', 'RB'), ('care', 'VB'), ('much', 'JJ'), ('...', ':'), (':(', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "tagged_tweet = nltk.pos_tag(cleaned_tweet)\n",
        "print(tagged_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "9HuwNuvnKQkf"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "tag_map = {'J': wn.ADJ, 'V': wn.VERB, 'R': wn.ADV, 'N': wn.NOUN}\n",
        "def get_lemmas(tokenized_text):\n",
        "    tagged_text = nltk.pos_tag(tokenized_text)\n",
        "    return [lemmatizer.lemmatize(w, pos=tag_map.get(p[0], wn.NOUN)) for (w, p) in tagged_text]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "JUy6lVVIKQkf",
        "outputId": "3b140664-fe50-4373-f6f5-55de2dd30d6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'fastest']\n"
          ]
        }
      ],
      "source": [
        "query = \"the fastest!\"\n",
        "normalized_query = normalize_tokens(tweet_tokenizer.tokenize(query))\n",
        "print(normalized_query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[lemmatizer.lemmatize(t) for t in ['the', 'fastest']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-C4KZFc-PE",
        "outputId": "4cadca15-5da6-43bf-8719-8a9a4be0980d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'fastest']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "6Kbi518yKQkf",
        "outputId": "536da9e8-ea76-43ab-c9e3-e42ef06f553e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'be', 'so', 'fast', 'i', 'be', 'the', 'fast']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "tweet = \"I am so fast, I am the fastest!\"\n",
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "# normalized_tweet\n",
        "# [lemmatizer.lemmatize(t) for t in normalized_tweet]\n",
        "get_lemmas(normalized_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "sDBprZDNKQkf",
        "outputId": "df3f9f36-1cde-4bee-de6c-a501e5c69598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'be', 'so', 'fast', 'i', 'be', 'the', 'fast']\n",
            "['the', 'fast']\n"
          ]
        }
      ],
      "source": [
        "lemmatized_tweet = get_lemmas(normalized_tweet)\n",
        "lemmatized_query = get_lemmas(normalized_query)\n",
        "print(lemmatized_tweet)\n",
        "print(lemmatized_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Y0s8GvLJKQkg",
        "outputId": "32bd8d86-47cd-41ed-fdd5-e3930735e9ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common words: {'the', 'fast'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Common words:\", set(lemmatized_tweet).intersection(set(lemmatized_query)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "t8pDhsOzKQkg",
        "outputId": "9215cd0d-ade6-4ac0-f730-5a6706a80670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fall',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'easily',\n",
              " 'care',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "get_lemmas(cleaned_tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0iax7YfKQkg"
      },
      "source": [
        "#### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "xptcX49SKQkg",
        "outputId": "93e9d209-e6c7-4a81-8974-e5271e45291a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 2), ('be', 2), ('fast', 2), ('so', 1), ('the', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(get_lemmas(normalized_tweet)).most_common(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "M28H3OvpKQkh",
        "outputId": "e5f44fb0-f4c7-4c3b-f08b-b294dbf321c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'be', 'so', 'fast', 'i', 'be', 'the', 'fast']\n"
          ]
        }
      ],
      "source": [
        "tweet = \"I am so fast, I am the fastest!\"\n",
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "lemmatized_tweet = get_lemmas(normalized_tweet)\n",
        "print(lemmatized_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "z6fNLVGDKQkh",
        "outputId": "fe445ff8-87f7-4bac-ef4e-7d378678100e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'i': 2, 'am': 2, 'so': 1, 'fast': 1, 'the': 1, 'fastest': 1})\n",
            "Counter({'i': 2, 'be': 2, 'fast': 2, 'so': 1, 'the': 1})\n"
          ]
        }
      ],
      "source": [
        "print(Counter(normalized_tweet))\n",
        "print(Counter(lemmatized_tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh6x8j4ZKQkh"
      },
      "source": [
        "#### Sentence segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "I37Pm2k1KQkh"
      },
      "outputs": [],
      "source": [
        "query = \"I am too fast. I am too furious.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "zIIdDtr4KQkh"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AOuAYg_KQki",
        "outputId": "321d2df4-6509-4fc2-b778-7d18e90e7178"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am too fast.', 'I am too furious.']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "sent_tokenize(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "oRTWDvNPKQki",
        "outputId": "3313a30c-ad73-425a-90bf-4f68418ee0da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Soy muy rápido!', 'Estoy muy furioso!']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "spanish_tokenizer = nltk.data.load('tokenizers/punkt/PY3/spanish.pickle')\n",
        "spanish_query = 'Soy muy rápido! Estoy muy furioso!'\n",
        "spanish_tokenizer.tokenize(spanish_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EuzgPvSKQki",
        "outputId": "ce17c6e8-863c-421c-bb3b-bbc34aef6472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J.K. Rowling is rich.', 'I am not as rich as J.K.']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "sent_tokenize(\"J.K. Rowling is rich. I am not as rich as J.K.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(\"J.K. Rowling is rich. I am not as rich as J.K. in the U.S.A.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6ZxcK3iyxu",
        "outputId": "dc4a0cd2-a9fc-438e-f89e-c556337ce962"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J.K.',\n",
              " 'Rowling',\n",
              " 'is',\n",
              " 'rich',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'not',\n",
              " 'as',\n",
              " 'rich',\n",
              " 'as',\n",
              " 'J.K.',\n",
              " 'in',\n",
              " 'the',\n",
              " 'U.S.A',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "8o1XY14fKQki"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "PunktSentenceTokenizer??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udCI1dkYKQkk"
      },
      "source": [
        "#### Numericalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "eNvpDCEHKQkk",
        "outputId": "bcbfaa62-e286-44ec-c710-ca3e487d631c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stay', 'tune']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "get_lemmas(normalize_tokens(custom_tokenizer.tokenize(\"STAY TUNED!\")))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I0iax7YfKQkg",
        "eh6x8j4ZKQkh",
        "udCI1dkYKQkk"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}