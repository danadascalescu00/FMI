{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqFwBVfAkYj4"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye564zd8B3r1",
        "outputId": "033ea4f1-07f0-4d7c-aaa5-fd3c527fb112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.64.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.10.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (5.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow-datasets) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.56.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Qe7PQAB3r3",
        "outputId": "d724980c-3635-4441-874a-e20fb5724e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.7.16)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.0)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.7/dist-packages (3.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension) (5.7.16)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (4.11.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (5.3.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (0.15.0)\n",
            "Requirement already satisfied: jupyter-client<7.0.0,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (6.1.12)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (0.13.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (5.1.1)\n",
            "Requirement already satisfied: tornado<7,>=4.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (6.0.4)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (5.7.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (23.2.1)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0.0,>=5.2.0->notebook>=4.4.1->widgetsnbextension) (2.8.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (2.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (0.8.4)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension) (4.13.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension) (4.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension) (3.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension) (0.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client<7.0.0,>=5.2.0->notebook>=4.4.1->widgetsnbextension) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension) (0.5.1)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension) (7.9.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (0.18.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets\n",
        "!pip install widgetsnbextension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A-CnqDF-kPta"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use tf.keras for tasks 1 and 2\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# Use keras for Tasks 3, 4, 5.\n",
        "from keras.layers import Dense,GlobalAveragePooling2D, Conv2D, Dropout, MaxPooling2D, Input, Flatten\n",
        "from keras.applications import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from ipywidgets import FloatProgress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_OazODvgwkN"
      },
      "source": [
        "## Task 0: Load the data\n",
        "tf.data.Dataset exposes about 29 preprocessed datasets for developers to easliy load and experiment with test datasets.\n",
        "\n",
        "For the first task, the focus is on tf_flowers. \n",
        "\n",
        "**0.1.** The tf_flowers dataset is not split into train, test and validation. So we need to do that by hand, using **tfds.Split.TRAIN.subsplit** method.\n",
        "\n",
        "**0.2.** Load the dataset using the **tfds.load()** method. Check the documentation for more options on the arguments. Two of the optional arguments that shall be used here are:\n",
        "- **with_info** - is True, which gives the metadata about the dataset.\n",
        "- **as_supervised** - is True, which returns the data and label as a tuple (input, label).\n",
        "\n",
        "**0.3.** Check out the metadata. From this we can see there are a total of 3670 images. After the split, 2950 training images are left.\n",
        "\n",
        "**0.4.** Pre-process the images. Define a function that resize each image to (32, 32), casts it to float and downscales the pixel values by 255. Map this function over the dataset.\n",
        "\n",
        "**0.5.** Use the map function to call the preprocessor on every element of the dataset.\n",
        "\n",
        "**0.6.** A few more operations on the dataset:\n",
        "  - i) Shuffle the training set. Use the SHUFFLE_BUFFER_SIZE constant as argument.\n",
        "  - ii) Batch all the three sets (train, validation and test).\n",
        "  - iii) Prefetch the training data in order to overcome the bottleneck b/w represented by the CPU.\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "757fcd12f07545be93a4e378d7591782",
            "0e2ffb143bae490480bb121b4bde8e61",
            "2f4097efd2ba4f5cb56f7e07e1bbd40e",
            "8c151157348348c786d440fc5a462b20",
            "7583de7cea9f4ba49dcc5c17fe953109",
            "de2d6900a12e4116ae420e7537d6176c",
            "9ae2bb70fceb40cb852757d03b0849a9",
            "8e284d21aca2416cbd3e17627c47a8be",
            "08da3da300f84d3ca668ec0e1d451c06",
            "6c66904a0f9940bea48d0b7bd2d08d7c",
            "2d1904b36c8e47f1a5aa5433a9ef6b98"
          ]
        },
        "id": "Cutw9kNyhcFv",
        "outputId": "597e09db-f1fb-4023-b8d8-8104bfb06dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to ~/tensorflow_datasets/tf_flowers/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "757fcd12f07545be93a4e378d7591782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset tf_flowers downloaded and prepared to ~/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\n",
            "Number of training samples 2936.0\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = 32\n",
        "IMG_HEIGHT = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1024\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 32\n",
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "SPLIT_WEIGHTS = (8, 1, 1)\n",
        "\n",
        "# 0.1. Use subsplit from tfds in order to split the tf_flowers dataset\n",
        "splits = [\"train[:80%]\",\"train[80%:90%]\",\"train[90%:]\"]     \n",
        "# 0.2. Load the datset\n",
        "(raw_train, raw_val, raw_test), metadata = tfds.load(\n",
        "                                                'tf_flowers',\n",
        "                                                split=splits,\n",
        "                                                with_info=True,\n",
        "                                                as_supervised=True)\n",
        "\n",
        "# 0.3. Check the metadata to find out the number of samples in each set\n",
        "num_train, num_val, num_test = (\n",
        "                                metadata.splits['train'].num_examples * weight/10 \\\n",
        "                                for weight in SPLIT_WEIGHTS\n",
        "                                )\n",
        "\n",
        "print('Number of training samples {}'.format(num_train))\n",
        "\n",
        "# 0.4. Define a method to pre-process the images\n",
        "def resize_normalize(img, label):\n",
        "    # i) TODO: Use tf.cast to convert the pixels to tf.float32\n",
        "    img = tf.cast(img, dtype=tf.float32)\n",
        "    # ii) TODO: Resize the image to the desired size: 32x32 (use the method from tf)\n",
        "    img = tf.image.resize(img, size=[32,32])\n",
        "    # iii) TODO: Normalize the pixel values: all channels are b/w 0 and 1\n",
        "    img = img / 255.\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# 0.5. Map the function defined above over the dataset (on each split)\n",
        "train = raw_train.map(resize_normalize)\n",
        "val = raw_val.map(resize_normalize)\n",
        "test = raw_test.map(resize_normalize)\n",
        "\n",
        "# # 0.6. Other preprocessings\n",
        "\n",
        "# # i) Shuffle the training size\n",
        "train = train.shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "\n",
        "# # ii) Batch each of the 3 sets: train, validation and test\n",
        "train = train.batch(BATCH_SIZE)\n",
        "val = val.batch(BATCH_SIZE)\n",
        "test = test.batch(BATCH_SIZE)\n",
        "\n",
        "# iii) Prefetch: AUTOTUNE.\n",
        "train = train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc60yGjO5pg8"
      },
      "source": [
        "## Task 1: Build a base model\n",
        "\n",
        "**1.1.** Define a convolutional neural network with the following architecture:\n",
        "  - **1.1.1.** 3 convolutional layers with 5x5 kernels, same padding and relu activation. After the 1st and 2nd CONV layers, add also MaxPooling, with filters of size 2.\n",
        "  - **1.1.2.** 2 fully connected layers: the first with 128 neurons and relu activation; the second should be used for classification, with softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tZCBqFaTKTg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5085b73-c969-4c38-a9ba-28809238bed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 64)          102464    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 681,221\n",
            "Trainable params: 681,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 1.1. Create the model\n",
        "def create_model():\n",
        "    img_inputs = keras.Input(shape=IMG_SHAPE)\n",
        "\n",
        "    # 1.1.1. Add 3 CONV layers, 5x5, same padding and relu activations; 32, 64, 64 neurons\n",
        "    conv_1 = Conv2D(32, kernel_size=5, padding='same', activation='relu')(img_inputs)\n",
        "    max_pooling1 = MaxPooling2D((2, 2))(conv_1)\n",
        "    conv_2 = Conv2D(64, kernel_size=5, padding='same', activation='relu')(max_pooling1)\n",
        "    max_pooling2 = MaxPooling2D((2, 2))(conv_2)\n",
        "    conv_3 = Conv2D(64, kernel_size=5, padding='same', activation='relu')(max_pooling2)\n",
        "\n",
        "    # 1.1.2. Flatten\n",
        "    flatten = keras.layers.Flatten()(conv_3)\n",
        "\n",
        "    # 1.1.3. Dense layers x 2: (128, relu), (5, softmax)\n",
        "    dense_1 = Dense(128, activation='relu')(flatten)\n",
        "    output = Dense(5, activation='softmax')(dense_1)\n",
        "\n",
        "    model = keras.Model(inputs=img_inputs, outputs=output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "base_model = create_model()\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5egBdjmZwOWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9aee5d3-adc0-4b93-c9d0-2500ad2312bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in the train set: 2936.0\n",
            "Number of examples in the validation set: 367.0\n",
            "Number of examples in the test set: 367.0\n"
          ]
        }
      ],
      "source": [
        "# Number of train, validation and test samples\n",
        "num_train, num_val, num_test = (\n",
        "  metadata.splits['train'].num_examples * weight/10 for weight in SPLIT_WEIGHTS\n",
        ")\n",
        "\n",
        "# Compute the number of steps per epoch such that all the train and validation sets are covered.\n",
        "steps_per_epoch = round(num_train) // BATCH_SIZE\n",
        "validation_steps = round(num_val) // BATCH_SIZE\n",
        "\n",
        "# Print the information about train, test and validation data\n",
        "print('Number of examples in the train set:', num_train)\n",
        "print('Number of examples in the validation set:', num_val)\n",
        "print('Number of examples in the test set:', num_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hFQSvfJgwi3"
      },
      "source": [
        "**1.2.** Train the network for a few iterations and save the model.\n",
        "  - **1.2.1.** Compile the model: adam, sparse_categorical_cross_entropy, accuracy as metric.\n",
        "  - **1.2.2.** Train. For the train and validation data use the repeat() function, to keep spinning the data and reuse it as the steps per epoch cause us to reach the end of the dataset. Please note that specifying the number of train and validation steps is mandatory in this case (when using repeat()).\n",
        "\n",
        "\n",
        "Note: \\\\\n",
        "Please take into account the fact that the amount of data is really small. Do not spend too much time trying to improve the performance of the model, as there are many other tasks left and those will give you more new knowledge to be further used and refined. The aim of this lab is to understand the know-hows of transfer learning and to be able to implement it. Not the performance of the models. Time permitting, you can, of course, do that as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2vW4Q2r7MXpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d04043-5763-44d5-ac0d-d96848cf047a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 19s 430ms/step - loss: 1.6122 - accuracy: 0.2438 - val_loss: 1.5954 - val_accuracy: 0.2425\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 277ms/step - loss: 1.5904 - accuracy: 0.2625 - val_loss: 1.5451 - val_accuracy: 0.3243\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 290ms/step - loss: 1.4803 - accuracy: 0.3469 - val_loss: 1.3510 - val_accuracy: 0.3951\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 1.3836 - accuracy: 0.4250 - val_loss: 1.3691 - val_accuracy: 0.4223\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 2s 241ms/step - loss: 1.3945 - accuracy: 0.4156 - val_loss: 1.2708 - val_accuracy: 0.4741\n"
          ]
        }
      ],
      "source": [
        "# 1.2. Train\n",
        "def train_model(model):\n",
        "    # 1.2.1. TODO: Compile\n",
        "    model.compile(\n",
        "        optimizer = 'adam',\n",
        "        loss = 'sparse_categorical_crossentropy',\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    # 1.2.2. TODO: Fit\n",
        "    train_data = train.repeat(12)\n",
        "    val_data = val.repeat(12)\n",
        "    history = model.fit(train_data, validation_data=val_data, steps_per_epoch=10, epochs=5, batch_size=32, shuffle=True)\n",
        "    \n",
        "    return history\n",
        "\n",
        "history = train_model(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "495OAp9l9eiv"
      },
      "source": [
        "## Task 2: Transfering to a new task\n",
        "\n",
        "**2.1.** Load the cifar10 dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dvknh4qV-ytF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef124b3-3609-4c21-e1b7-7a6e6359c112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "\n",
        "# 2.1. Load cifar10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIn6OK8x_n8n"
      },
      "source": [
        "**2.2.** Keep all the convolutional and max pooling layers from the base model (trained on tf flowers). On top of them we will define two new dense layers and train the entire model on the new dataset.\n",
        "  - **2.2.1.** If your first model followed the specified architecture, the flattening layer applied after the convolutions should be model.layer[-3] to get its output we simply use model.layers[-3].output.\n",
        "  - **2.2.2.** Build 2 new fully connected layers on top of the base model.\n",
        "\n",
        "**2.3.** Define a new model that outputs the result from our newly created layers. Use **tf.keras.model**.\n",
        "\n",
        "**2.4.** Compile the new model: Adam as optimizer, loss sparse categorical crossentropy, accuracy as metric.\n",
        "\n",
        "**2.5.** Train the new model on cifar10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TKptYr8vBZI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94890842-aa75-4be9-e40b-b5f1046a12af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model's weights:  10\n",
            "Trainable weights:  10\n",
            "Non-trainable weights:  0\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.6014 - accuracy: 0.4384 - val_loss: 1.3842 - val_accuracy: 0.5078\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2808 - accuracy: 0.5488 - val_loss: 1.3305 - val_accuracy: 0.5403\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1560 - accuracy: 0.5951 - val_loss: 1.2389 - val_accuracy: 0.5718\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0578 - accuracy: 0.6318 - val_loss: 1.1477 - val_accuracy: 0.6021\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9801 - accuracy: 0.6577 - val_loss: 1.1680 - val_accuracy: 0.6084\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9252 - accuracy: 0.6800 - val_loss: 1.1649 - val_accuracy: 0.6154\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8598 - accuracy: 0.7004 - val_loss: 1.1392 - val_accuracy: 0.6408\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8084 - accuracy: 0.7170 - val_loss: 1.2590 - val_accuracy: 0.6073\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7568 - accuracy: 0.7379 - val_loss: 1.2325 - val_accuracy: 0.6276\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7245 - accuracy: 0.7507 - val_loss: 1.2432 - val_accuracy: 0.6379\n"
          ]
        }
      ],
      "source": [
        "# 2.2. Reuse the base model\n",
        "print(\"Base model's weights: \", len(base_model.weights))\n",
        "print(\"Trainable weights: \", len(base_model.trainable_weights))\n",
        "print(\"Non-trainable weights: \", len(base_model.non_trainable_weights))\n",
        "\n",
        "# 2.2.1. Keep only the convolutional and max pooling layers from the base model.\n",
        "x = base_model.input\n",
        "conv_output = base_model.layers[-3].output\n",
        "\n",
        "# 2.2.2. Build new layers on top of the base model (e.g. (relu, 128 neurons), (10, softmax)\n",
        "fc_1 = Dense(128, activation='relu')(conv_output)\n",
        "fc_2 = Dense(10, activation='softmax')(fc_1)\n",
        "\n",
        "# 2.3. Define a new model that outputs the result from our newly created layers\n",
        "new_model = tf.keras.Model(x, fc_2)\n",
        "\n",
        "# 2.4. Compile the model: TODO\n",
        "new_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 2.5. Train on cifar\n",
        "new_history = new_model.fit(x=x_train, y=y_train,\n",
        "                            batch_size=32, epochs=10,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07G3BLs5kr1a"
      },
      "source": [
        "## Task 3: Loading Keras Pretrained Models\n",
        "\n",
        "### STEP 1: Build the model\n",
        "\n",
        "**3.1.** Load the ResNet50 model from Keras, pretrained on ImageNet (a dataset with 1000 classes and millions of training examples). \n",
        "\n",
        "**3.2.** The ResNet50 model has 1000 neurons in the last layer (one for each class). We want as many neurons in the last layer of the network as the number of classes in the current problem. Thus we need to discard the 1000 neuron layer and add our own last layer.\n",
        "*Hint*: Set *IncludeTop=False* when importing the model.\n",
        "\n",
        "**3.3.** Add a few **dense layers** such that our model learns more complex functions. The dense layers have **relu as activation** function and the **last layer**, with **as many neurons as the number of classes** has **softmax as activation**.\n",
        "\n",
        "**3.4.** Build a model on the architecture provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wPAhS2eD-RYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab461131-f81d-49ec-f72f-f89f29a33dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/flower_photos\n"
          ]
        }
      ],
      "source": [
        "# Download the flowers dataset\n",
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, \n",
        "                                   fname=\"flower_photos.tgz\", \n",
        "                                   extract=True)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')\n",
        "print(base_dir)\n",
        "\n",
        "# Some constants\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rvg0cAGH8EAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7a8da3-00ad-4c61-e192-4b5acae72311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_15\n",
            "1 conv1_pad\n",
            "2 conv1_conv\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 pool1_pad\n",
            "6 pool1_pool\n",
            "7 conv2_block1_1_conv\n",
            "8 conv2_block1_1_bn\n",
            "9 conv2_block1_1_relu\n",
            "10 conv2_block1_2_conv\n",
            "11 conv2_block1_2_bn\n",
            "12 conv2_block1_2_relu\n",
            "13 conv2_block1_0_conv\n",
            "14 conv2_block1_3_conv\n",
            "15 conv2_block1_0_bn\n",
            "16 conv2_block1_3_bn\n",
            "17 conv2_block1_add\n",
            "18 conv2_block1_out\n",
            "19 conv2_block2_1_conv\n",
            "20 conv2_block2_1_bn\n",
            "21 conv2_block2_1_relu\n",
            "22 conv2_block2_2_conv\n",
            "23 conv2_block2_2_bn\n",
            "24 conv2_block2_2_relu\n",
            "25 conv2_block2_3_conv\n",
            "26 conv2_block2_3_bn\n",
            "27 conv2_block2_add\n",
            "28 conv2_block2_out\n",
            "29 conv2_block3_1_conv\n",
            "30 conv2_block3_1_bn\n",
            "31 conv2_block3_1_relu\n",
            "32 conv2_block3_2_conv\n",
            "33 conv2_block3_2_bn\n",
            "34 conv2_block3_2_relu\n",
            "35 conv2_block3_3_conv\n",
            "36 conv2_block3_3_bn\n",
            "37 conv2_block3_add\n",
            "38 conv2_block3_out\n",
            "39 conv3_block1_1_conv\n",
            "40 conv3_block1_1_bn\n",
            "41 conv3_block1_1_relu\n",
            "42 conv3_block1_2_conv\n",
            "43 conv3_block1_2_bn\n",
            "44 conv3_block1_2_relu\n",
            "45 conv3_block1_0_conv\n",
            "46 conv3_block1_3_conv\n",
            "47 conv3_block1_0_bn\n",
            "48 conv3_block1_3_bn\n",
            "49 conv3_block1_add\n",
            "50 conv3_block1_out\n",
            "51 conv3_block2_1_conv\n",
            "52 conv3_block2_1_bn\n",
            "53 conv3_block2_1_relu\n",
            "54 conv3_block2_2_conv\n",
            "55 conv3_block2_2_bn\n",
            "56 conv3_block2_2_relu\n",
            "57 conv3_block2_3_conv\n",
            "58 conv3_block2_3_bn\n",
            "59 conv3_block2_add\n",
            "60 conv3_block2_out\n",
            "61 conv3_block3_1_conv\n",
            "62 conv3_block3_1_bn\n",
            "63 conv3_block3_1_relu\n",
            "64 conv3_block3_2_conv\n",
            "65 conv3_block3_2_bn\n",
            "66 conv3_block3_2_relu\n",
            "67 conv3_block3_3_conv\n",
            "68 conv3_block3_3_bn\n",
            "69 conv3_block3_add\n",
            "70 conv3_block3_out\n",
            "71 conv3_block4_1_conv\n",
            "72 conv3_block4_1_bn\n",
            "73 conv3_block4_1_relu\n",
            "74 conv3_block4_2_conv\n",
            "75 conv3_block4_2_bn\n",
            "76 conv3_block4_2_relu\n",
            "77 conv3_block4_3_conv\n",
            "78 conv3_block4_3_bn\n",
            "79 conv3_block4_add\n",
            "80 conv3_block4_out\n",
            "81 conv4_block1_1_conv\n",
            "82 conv4_block1_1_bn\n",
            "83 conv4_block1_1_relu\n",
            "84 conv4_block1_2_conv\n",
            "85 conv4_block1_2_bn\n",
            "86 conv4_block1_2_relu\n",
            "87 conv4_block1_0_conv\n",
            "88 conv4_block1_3_conv\n",
            "89 conv4_block1_0_bn\n",
            "90 conv4_block1_3_bn\n",
            "91 conv4_block1_add\n",
            "92 conv4_block1_out\n",
            "93 conv4_block2_1_conv\n",
            "94 conv4_block2_1_bn\n",
            "95 conv4_block2_1_relu\n",
            "96 conv4_block2_2_conv\n",
            "97 conv4_block2_2_bn\n",
            "98 conv4_block2_2_relu\n",
            "99 conv4_block2_3_conv\n",
            "100 conv4_block2_3_bn\n",
            "101 conv4_block2_add\n",
            "102 conv4_block2_out\n",
            "103 conv4_block3_1_conv\n",
            "104 conv4_block3_1_bn\n",
            "105 conv4_block3_1_relu\n",
            "106 conv4_block3_2_conv\n",
            "107 conv4_block3_2_bn\n",
            "108 conv4_block3_2_relu\n",
            "109 conv4_block3_3_conv\n",
            "110 conv4_block3_3_bn\n",
            "111 conv4_block3_add\n",
            "112 conv4_block3_out\n",
            "113 conv4_block4_1_conv\n",
            "114 conv4_block4_1_bn\n",
            "115 conv4_block4_1_relu\n",
            "116 conv4_block4_2_conv\n",
            "117 conv4_block4_2_bn\n",
            "118 conv4_block4_2_relu\n",
            "119 conv4_block4_3_conv\n",
            "120 conv4_block4_3_bn\n",
            "121 conv4_block4_add\n",
            "122 conv4_block4_out\n",
            "123 conv4_block5_1_conv\n",
            "124 conv4_block5_1_bn\n",
            "125 conv4_block5_1_relu\n",
            "126 conv4_block5_2_conv\n",
            "127 conv4_block5_2_bn\n",
            "128 conv4_block5_2_relu\n",
            "129 conv4_block5_3_conv\n",
            "130 conv4_block5_3_bn\n",
            "131 conv4_block5_add\n",
            "132 conv4_block5_out\n",
            "133 conv4_block6_1_conv\n",
            "134 conv4_block6_1_bn\n",
            "135 conv4_block6_1_relu\n",
            "136 conv4_block6_2_conv\n",
            "137 conv4_block6_2_bn\n",
            "138 conv4_block6_2_relu\n",
            "139 conv4_block6_3_conv\n",
            "140 conv4_block6_3_bn\n",
            "141 conv4_block6_add\n",
            "142 conv4_block6_out\n",
            "143 conv5_block1_1_conv\n",
            "144 conv5_block1_1_bn\n",
            "145 conv5_block1_1_relu\n",
            "146 conv5_block1_2_conv\n",
            "147 conv5_block1_2_bn\n",
            "148 conv5_block1_2_relu\n",
            "149 conv5_block1_0_conv\n",
            "150 conv5_block1_3_conv\n",
            "151 conv5_block1_0_bn\n",
            "152 conv5_block1_3_bn\n",
            "153 conv5_block1_add\n",
            "154 conv5_block1_out\n",
            "155 conv5_block2_1_conv\n",
            "156 conv5_block2_1_bn\n",
            "157 conv5_block2_1_relu\n",
            "158 conv5_block2_2_conv\n",
            "159 conv5_block2_2_bn\n",
            "160 conv5_block2_2_relu\n",
            "161 conv5_block2_3_conv\n",
            "162 conv5_block2_3_bn\n",
            "163 conv5_block2_add\n",
            "164 conv5_block2_out\n",
            "165 conv5_block3_1_conv\n",
            "166 conv5_block3_1_bn\n",
            "167 conv5_block3_1_relu\n",
            "168 conv5_block3_2_conv\n",
            "169 conv5_block3_2_bn\n",
            "170 conv5_block3_2_relu\n",
            "171 conv5_block3_3_conv\n",
            "172 conv5_block3_3_bn\n",
            "173 conv5_block3_add\n",
            "174 conv5_block3_out\n",
            "175 global_average_pooling2d_10\n",
            "176 dense_36\n",
            "177 dense_37\n",
            "178 dense_38\n",
            "Trainable layers:  122\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "  Reference: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "\"\"\"\n",
        "\n",
        "# 3.1. Import the model, 3.2. without the last layer\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
        "                                            include_top=False)\n",
        "\n",
        "# base_model.trainable = False\n",
        "base_model.trainable= True\n",
        "\n",
        "inputs = base_model.input\n",
        "x = base_model.output\n",
        "\n",
        "# Add GlobalAveragePooling\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# 3.3. i) Add 2 dense layers: 32, 32, relu\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "\n",
        "# 3.3. ii) Add a final dense layer: 5, softmax\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "# 3.4. Build the model\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# Uncomment below to check the architecture of the model\n",
        "for i,layer in enumerate(model.layers):\n",
        "   print(i,layer.name)\n",
        "\n",
        "# TASK 4/5: Play later with freezing/unfreezing some or all the layers of the base network\n",
        "for layer in model.layers[:80]:\n",
        "  layer.trainable=False\n",
        "\n",
        "print(\"Trainable layers: \", len(model.trainable_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9NOHDFyIL8G"
      },
      "source": [
        "### Step 2: Load the training data into the ImageDataGenerator\n",
        "\n",
        "ImageDataGeneator is a class from keras, that can help us to train our model. All we need to do is specify the path to our training data and it automatically sends the data for training, in batches. It makes the code much simpler. \n",
        "\n",
        "**3.5.** Use ImageDataGenerator with rescale 1./255 and validation split of 0.2 (80/20).\n",
        "\n",
        "**3.6.** Create the train generator and specify where the train dataset directory, image size, batch size.\n",
        "\n",
        "**3.7.** Create the validation generator with similar approach as the train generator with the flow_from_directory() method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "W5apuCBjDE_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ec35ca-763e-426e-9bc2-cab5d2bc664b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2939 images belonging to 5 classes.\n",
            "Found 731 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3.5. Rescale the images using ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
        "\n",
        "# 3.6. Use flow_from_directory to specify the base_dir, target_size, batch_size and subset: 'training'\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# 3.7. For subset: 'validation', use a similar approach as in 3.6.\n",
        "val_generator = train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNDw9mzwINTj"
      },
      "source": [
        "### STEP 3: Train on the dataset\n",
        "\n",
        "**3.8.**  Compile the model using **categorical crossentropy**, **accuracy as metric** and **Adam as optimizer**.\n",
        "\n",
        "**3.9.** Train using **train_generator** as **generator**, **step_size_train** as **steps_per_epoch**, and **10 epochs**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "J14Kb6ChIOzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548554df-d491-4192-9d07-839c650a32a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " global_average_pooling2d_10 (G  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 32)           65568       ['global_average_pooling2d_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, 32)           1056        ['dense_36[0][0]']               \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, 5)            165         ['dense_37[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,654,501\n",
            "Trainable params: 22,151,397\n",
            "Non-trainable params: 1,503,104\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 13s 432ms/step - loss: 1.6264 - accuracy: 0.3150 - val_loss: 18135.2344 - val_accuracy: 0.1724\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 8s 380ms/step - loss: 1.5481 - accuracy: 0.3150 - val_loss: 754.0957 - val_accuracy: 0.2025\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 8s 379ms/step - loss: 1.4295 - accuracy: 0.3969 - val_loss: 325.7257 - val_accuracy: 0.1902\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 8s 389ms/step - loss: 1.4025 - accuracy: 0.4205 - val_loss: 130.4861 - val_accuracy: 0.2175\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 8s 381ms/step - loss: 1.3720 - accuracy: 0.4409 - val_loss: 98.1335 - val_accuracy: 0.1902\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 8s 377ms/step - loss: 1.3319 - accuracy: 0.4772 - val_loss: 30.9174 - val_accuracy: 0.1902\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 7s 376ms/step - loss: 1.3074 - accuracy: 0.5055 - val_loss: 30.6671 - val_accuracy: 0.2052\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 8s 390ms/step - loss: 1.2171 - accuracy: 0.4945 - val_loss: 16.2169 - val_accuracy: 0.2134\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 7s 376ms/step - loss: 1.1566 - accuracy: 0.5402 - val_loss: 24.4440 - val_accuracy: 0.2271\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 8s 377ms/step - loss: 1.1165 - accuracy: 0.5638 - val_loss: 21.5525 - val_accuracy: 0.2202\n"
          ]
        }
      ],
      "source": [
        "# 3.8. TODO: Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 3.9. Train the model\n",
        "history = model.fit(train_generator, validation_data=val_generator, steps_per_epoch=20, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPFmfG1mnAXs",
        "outputId": "3c9dcfad-8bf6-4f8d-adc6-30b047dd8e14"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "V6Zu17mpMLfb"
      },
      "outputs": [],
      "source": [
        "# Plot the learning curves\n",
        "def plot_lc(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([min(plt.ylim()),1])\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.ylabel('Cross Entropy')\n",
        "    plt.ylim([0,13.0])\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "P2e7BIIuMX18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "c083a2ce-17f8-4957-9188-af52a316820c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHwCAYAAAC2blbYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxV1b3//9eHhMwBMjAmDEERBBWQABWtgtN1hDpVqRN6Ha9DtbfV2tbWa29v/bb9dbC1eqm1SktFa6sXW6datVpxIA5tBUUpBAmTEEgIJCHT5/fH3gknIQkJ5uTkJO/n43Ee2cPae3/OTnI+e629zl7m7oiIiEj86RfrAEREROTAKImLiIjEKSVxERGROKUkLiIiEqeUxEVEROKUkriIiEicUhKXPsXMnjazS7u6bCyZWbGZnRiF/b5kZleE0xea2XMdKXsAxxllZrvMLOFAYxXpq5TEpccLP+AbXw1mVhUxf2Fn9uXup7r7Q11dticys6+a2cutLM81sxozO6yj+3L3xe5+chfF1eyiw90/dvcMd6/viv23cjwzszVmtjIa+xeJJSVx6fHCD/gMd88APgbOjFi2uLGcmSXGLsoe6TfALDMraLH8AuCf7v5eDGKKhWOBIcBYM5venQfW36REm5K4xC0zm21mJWZ2q5ltBn5lZllm9kcz22pmO8Lp/IhtIpuIF5jZ38zsB2HZtWZ26gGWLTCzl82swsyeN7N7zOw3bcTdkRi/bWavhvt7zsxyI9ZfbGbrzKzUzL7e1vlx9xLgBeDiFqsuARbtL44WMS8ws79FzJ9kZh+YWbmZ/QywiHUHmdkLYXzbzGyxmQ0K1/0aGAU8Gbak3GJmY8zMGxOemY0ws6Vmtt3MVpvZlRH7vsPMHjWzReG5WWFmhW2dg9ClwP8BT4XTke9rkpn9OTzWFjP7Wrg8wcy+Zmb/Co/zlpmNbBlrWLbl38mrZvYjMysF7mjvfITbjDSzP4S/h1Iz+5mZJYUxHR5RboiZVZrZ4P28X+lDlMQl3g0DsoHRwFUEf9O/CudHAVXAz9rZfiawCsgFvgf80szsAMr+FngTyAHuYN/EGakjMX4BuIygBpkEfBnAzCYC94b7HxEer9XEG3ooMhYzGw9MCePt7Llq3Ecu8AfgGwTn4l/A0ZFFgO+G8R0KjCQ4J7j7xTRvTfleK4dYApSE258L/I+ZHR+xfm5YZhCwtL2YzSwt3Mfi8HWBmSWF6zKB54FnwmMdDPwl3PRLwHzgNGAAcDlQ2e6J2WsmsAYYCnynvfNhQT+APwLrgDFAHrDE3WvC93hRxH7nA39x960djEP6AnfXS6+4eQHFwInh9GygBkhpp/wUYEfE/EvAFeH0AmB1xLo0wIFhnSlLkADrgLSI9b8BftPB99RajN+ImP8P4Jlw+psEH/KN69LDc3BiG/tOA3YCs8L57wD/d4Dn6m/h9CXA6xHljCDpXtHGfj8HvNPa7zCcHxOey0SCBFcPZEas/y7wYDh9B/B8xLqJQFU75/YiYGu47xSgHDgrXDc/Mq4W260C5rWyvCnWds7Tx/v5fTedD+CoxvhaKTeT4ILHwvki4POx/P/Tq+e9VBOXeLfV3asbZ8wszcz+N2xu3gm8DAyytns+b26ccPfGmlZGJ8uOALZHLANY31bAHYxxc8R0ZURMIyL37e67gdK2jhXG9DvgkrDV4EJgUSfiaE3LGDxy3syGmtkSM9sQ7vc3BDX2jmg8lxURy9YR1FAbtTw3Kdb2vedLgUfdvS78O/k9e5vURxK0IrSmvXX70+x3v5/zMRJY5+51LXfi7m8QvL/ZZjaBoKVg6QHGJL2UkrjEu5bD8P0nMB6Y6e4DCDo1QcQ92yjYBGSHTbeNRrZT/tPEuCly3+Exc/azzUPA54GTgEzgyU8ZR8sYjObv938Ifi+Hh/u9qMU+2xs6cSPBucyMWDYK2LCfmPYR3t8/HrjIzDZb0G/iXOC08JbAemBsG5uvBw5qZfnu8Gfk73pYizIt319752M9MKqdi5CHwvIXA49FXrCKgJK49D6ZBPd2y8wsG/hWtA/o7usImjrvCDskHQWcGaUYHwPOMLNjwnu7d7L//+NXgDJgIXvvt36aOP4ETDKzs8PkcyPNE1kmsAsoN7M84Csttt9CG8nT3dcDy4DvmlmKmR0B/DtB7bWzLgY+JLhQmRK+DiFo+p9PcC96uJndZGbJZpZpZjPDbe8Hvm1m4yxwhJnleHA/egPBhUGCmV1O68k+Unvn402Ci6K7zCw9fM+R/Qt+A5xFkMgXHcA5kF5OSVx6mx8DqcA24HWCTkvd4UKC+5ulwH8DjwB72ih7wDG6+wrgOoKOaZuAHQRJqb1tnCABjKZ5IjigONx9G3AecBfB+x0HvBpR5L+AIwnuP/+JoBNcpO8C3zCzMjP7ciuHmE9w73kj8DjwLXd/viOxtXAp8HN33xz5Au4DLg2b7E8iuODaDHwEzAm3/SHwKPAcQZ+CXxKcK4ArCRJxKTCJ4KKjPW2eDw++G38mQVP5xwS/y/Mj1q8H3iaoyb/S+VMgvV1jhwkR6UJm9gjwgbtHvSVAejczewDY6O7fiHUs0vMoiYt0AQseIrIdWAucDDwBHOXu78Q0MIlrZjYGeBeY6u5rYxuN9ERRa043swfM7BMza/WpUOF9prsteJjDP8zsyGjFItINhhF81WgXcDdwrRK4fBpm9m3gPeD7SuDSlqjVxM3sWIIPtEXuvs8zms3sNOAGgocpzAR+4u4zW5YTERGR1kWtJu7uLxM0L7ZlHkGCd3d/neD7qcOjFY+IiEhvE8ve6Xk0fyhCCc0f6CAiIiLtiIsRdszsKoLnYpOenj5twoQJMY5IRESke7z11lvb3L3VgW9imcQ30PwpT/m08VQmd19I8KAKCgsLvaioKPrRiYiI9ABmtq6tdbFsTl9K+DxnM/sMUO7um2IYj4iISFyJWk3czB4mGGUq18xKCB7p2B/A3e8jGNv3NGA1wUP+L4tWLCIiIr1R1JK4u8/fz3oneHykiIiIHAA9O11ERCROKYmLiIjEKSVxERGROKUkLiIiEqeUxEVEROKUkriIiEicUhIXERGJU0riIiIicUpJXEREJE4piYuIiMQpJXEREZE4pSQuIiISp5TERURE4pSSuIiISJxSEhcREYlTUU3iZnaKma0ys9Vm9tVW1o82s7+Y2T/M7CUzy49mPCIiIr1J1JK4mSUA9wCnAhOB+WY2sUWxHwCL3P0I4E7gu9GKR0REpLeJZk18BrDa3de4ew2wBJjXosxE4IVw+sVW1ouIiEgbopnE84D1EfMl4bJIfwfODqfPAjLNLKfljszsKjMrMrOirVu3RiVYERGReBPrjm1fBo4zs3eA44ANQH3LQu6+0N0L3b1w8ODB3R2jiIhIj5QYxX1vAEZGzOeHy5q4+0bCmriZZQDnuHtZFGMSERHpNaJZE18OjDOzAjNLAi4AlkYWMLNcM2uM4TbggSjGIyIi0qtELYm7ex1wPfAs8D7wqLuvMLM7zWxuWGw2sMrMPgSGAt+JVjwiIiK9jbl7rGPolMLCQi8qKop1GCIiIt3CzN5y98LW1sW6Y5uIiIgcICVxERGROKUkLiIiEqeUxEVEROKUkriIiEicUhIXERGJU0riIiIicUpJXEREJE4piYuIiMQpJXEREZE4pSQuIiISp5TERURE4pSSuIiISJxSEhcREYlTUU3iZnaKma0ys9Vm9tVW1o8ysxfN7B0z+4eZnRbNeERERHqTqCVxM0sA7gFOBSYC881sYoti3wAedfepwAXAz6MVj4iISG8TzZr4DGC1u69x9xpgCTCvRRkHBoTTA4GNUYxHRESkV0mM4r7zgPUR8yXAzBZl7gCeM7MbgHTgxCjGIyIi0qvEumPbfOBBd88HTgN+bWb7xGRmV5lZkZkVbd26tduDFBER6YmimcQ3ACMj5vPDZZH+HXgUwN1fA1KA3JY7cveF7l7o7oWDBw+OUrgiIiLxJZpJfDkwzswKzCyJoOPa0hZlPgZOADCzQwmSuKraIiIiHRC1JO7udcD1wLPA+wS90FeY2Z1mNjcs9p/AlWb2d+BhYIG7e7RiEhER6U2i2bENd38KeKrFsm9GTK8Ejo5mDCIiIr1VrDu2iYiIyAFSEhcREYlTSuIiIiJxSklcREQkTimJi4iIxCklcRERkTilJC4iIhKnlMRFRETilJK4iIhInFISFxERiVNK4iIiInFKSVxERCROKYmLiIjEKSVxERGROBXVJG5mp5jZKjNbbWZfbWX9j8zs3fD1oZmVRTMeERGR3iRq44mbWQJwD3ASUAIsN7Ol4RjiALj7zRHlbwCmRiseERGR3iaaNfEZwGp3X+PuNcASYF475ecDD0cxHhERkV4lmkk8D1gfMV8SLtuHmY0GCoAXohiPiIhIr9JTOrZdADzm7vWtrTSzq8ysyMyKtm7d2s2hiYiI9EzRTOIbgJER8/nhstZcQDtN6e6+0N0L3b1w8ODBXRiiiIhI/IpmEl8OjDOzAjNLIkjUS1sWMrMJQBbwWhRjERER6XWilsTdvQ64HngWeB941N1XmNmdZjY3ougFwBJ392jFIiIi0htF7StmAO7+FPBUi2XfbDF/RzRjEBER6a16Ssc2ERER6SQlcRERkTilJC4iIhKn9pvEzexMM1OyFxER6WE6kpzPBz4ys++FXwcTERGRHmC/SdzdLyIYmORfwINm9lr4BLXMqEcnIiIibepQM7m77wQeIxjEZDhwFvB2OPKYiIiIxEBH7onPNbPHgZeA/sAMdz8VmAz8Z3TDExERkbZ05GEv5wA/cveXIxe6e6WZ/Xt0whIREZH96UgSvwPY1DhjZqnAUHcvdve/RCswERERaV9H7on/DmiImK8Pl4mIiEgMdSSJJ7p7TeNMOJ0UvZBERESkIzqSxLdGjjpmZvOAbdELSURERDqiI/fErwEWm9nPAAPWA5dENSoRERHZr/0mcXf/F/AZM8sI53dFPSoRERHZrw6NJ25mpwOTgBQzA8Dd7+zAdqcAPwESgPvd/a5WynyeoAe8A3939y90NHgREZG+bL9J3MzuA9KAOcD9wLnAmx3YLgG4BzgJKAGWm9lSd18ZUWYccBtwtLvvMLMhB/QuRERE+qCOdGyb5e6XADvc/b+Ao4BDOrDdDGC1u68Je7QvAea1KHMlcI+77wBw9086HrqIiEjf1pEkXh3+rDSzEUAtwfPT9yePoBNco5JwWaRDgEPM7FUzez1sft9HOOBKkZkVbd26tQOHFhER6f06ksSfNLNBwPeBt4Fi4LdddPxEYBwwG5gP/CI8VjPuvtDdC929cPDgwV10aBERkfjW7j1xM+sH/MXdy4Dfm9kfgRR3L+/AvjcAIyPm88NlkUqAN9y9FlhrZh8SJPXlHX0DIiIifVW7NXF3byDonNY4v6eDCRyCRDzOzArMLAm4AFjaoswTBLVwzCyXoHl9TQf3LyIi0qd1pDn9L2Z2jjV+t6yD3L0OuB54FngfeNTdV5jZnRFPgHsWKDWzlcCLwFfcvbQzxxEREemrzN3bL2BWAaQDdQSd3Axwdx8Q/fD2VVhY6EVFRbE4tIiISLczs7fcvbC1dR15Yltm14ckIiIin1ZHHvZybGvL3f3lrg9HREQkfjU0OOVVtWSld89gnx157OpXIqZTCB7i8hZwfFQiEhER6aHq6hvYvLOaDTuqKNlRxYayKjaEP0t2VLKxrJrMlETeuv2kbomnI83pZ0bOm9lI4MdRi0hERCRG9tTVs6msOkzQlU3JuiRM1pt3VlPf0LwvWW5GMnlZqUwaMZB/mzSM/KxU3J1O9gc/IB0aAKWFEuDQrg5EREQk2ipr6oLEXBbWpCNq0Rt2VPFJxZ5m5fsZDB2QQn5WKtPHZJGXlUp+Vhp5g1LJy0olb1AqKf0TYvRuOnZP/KcEI4xB8JW0KQRPbhMREelRyqtqw9pzZVNTd1Ozd1kV23fXNCvfP8EYPjBIxscdMrgpMednpZGflcqwgSn0T+jIt7FjoyM18cjvc9UBD7v7q1GKR0REpFXuTunumn1qzxsiatUVe+qabZOc2I/8rFTystI4LG8g+VmpwXyYqAdnJpPQL/rN3tHSkST+GFDt7vUQDDFqZmnuXhnd0EREpC+qb3A+2LyTouIdrNpSESbooGZdXdvQrGxmcmLYxJ3KzILsfZq7c9KTuuXedKx0JIn/BTgR2BXOpwLPAbOiFZSIiPQd1bX1/H19GUXrdvDm2u28vW5HU406K60/+VlpjBuSyZzxQ5qauxuT9cDU/jGOPrY6ksRT3L0xgePuu8wsLYoxiYhIL1ZeWUvRuu0sL97B8uLt/LOknJr6oIY9bkgGZ0wewYyCLApHZ5Ofldqra9KfVkeS+G4zO9Ld3wYws2lAVXTDEhGR3mJjWRXLi7cHr7VBEzlAYj/j8PyBLDh6DNPHZFM4OqvbHpLSW3Qkid8E/M7MNhI8N30YcH5UoxIRkbjU0OCs3rqLN9dup6g4qG1vKAvqfelJCRw5OoszjhhO4ZhspowcRGpS7L6e1Rt05GEvy81sAjA+XLQqHP9bRET6uJq6Bv65oZzlxUHSLlq3g7LKIEXkZiQzoyCLKz5bwPQx2UwYlkliD/66VjzqyPfErwMWu/t74XyWmc13959HPToREelRKqprefvjMpavDZrH311fxp664H722Nx0Tp44lOljspk+JpvROWm6nx1lHWlOv9Ld72mccfcdZnYlsN8kbmanAD8BEoD73f2uFusXAN8HNoSLfubu93cwdhERibJPdlY3dUBbXryd9zftpMEhoZ8xacQALpw5mhkFWUwbnc3gzORYh9vndCSJJ5iZeTjwuJklAPvteRCWuwc4ieBRrcvNbKm7r2xR9BF3v76TcYuIdKuGBmdLRTVrt+5mbeluausayEzpT0ZKIpkpiQxI6U9GcjCdkZJIcmL83et1d9Zs201R8XbeXLuDonXbWVcaPBIktX8CU0cN4vrjxzFjTDZTRg0iI/lAntwtXakjv4FngEfM7H/D+auBpzuw3QxgtbuvATCzJcA8oGUSFxHpERqfCFa8bTdrtu2meNtu1oav4tLd+zxopD1Jif0YkJIYJva9CT4zpX/4c++6xsQ/IKV52fSkRPpF8WlidfUNrNi4s6mWXVS8g9LwsaTZ6UkUjs7iopmjmV6QzaQRA3r040f7qo4k8VuBq4Brwvl/EPRQ3588YH3EfAkws5Vy54Rjln8I3Ozu61spIyLSZXZW1zYl6DVbgwTdmKwrqvc+tjOxnzEqO40xuekcfXAuBbnpFOSmMyY3nZTEfuzaU0dFdR07q2vZVR1MB8tqqaiuoyJcvyucX1daya49Yfk9dbi3EyRgBhlJe2v3rV4MJO9d1zgf2UKQGdEqUFlTx7sfl/FmmLDf/ngHlTX1AIzMTuW48YOb7mcfNDhd97PjQEd6pzeY2RvAQcDngVzg9110/CcJnsW+x8yuBh6ilXHKzewqggsJRo0a1UWHFpHerKqmnuLS3fvUqotLd7Nt195BMMxgxMBUxg5O53NT8poSdUFuOvlZqe32ps7JOPB7wA0NTmVtPRXhBcDOFhcAwUVBbdOFQEWY+HdU1rB+eyU7w2WNncrak5TQj8yURMqraqlrcMxgwrABnDctn8IwaQ8bmHLA70Vip80kbmaHAPPD1zbgEQB3n9PBfW8ARkbM57O3AxvhvkojZu8Hvtfajtx9IbAQoLCwcD/XriLSV9TUNbB+RyVrw9p0ZLLeVF7drOzgzGQKctM58dChjIlI1KOy02IylGS/fkZGctCkzsAD309NXQO79tSFFwK1zVoDdjVdAATzg9L6Uzgmm2mjsxiQ0rcfV9pbtFcT/wB4BTjD3VcDmNnNndj3cmCcmRUQJO8LgC9EFjCz4e6+KZydC7zfif2LSB9Q3+BsLKtqqkVHNn+X7KiivmHvdf3A1P4U5KZz1NicZol6TG56r+2ElZTYj+zEJLL1pLM+qb2/6rMJEu+LZvYMsITgiW0d4u51ZnY98CzBV8wecPcVZnYnUOTuS4EbzWwuwRCn24EFB/Y2RCSeuTufVOzZ24ksogl8XWll03O1AdKSEijITeewvIHMnTyCMTnpFAxOpyAnXY/slD7HfD89K8wsnaBX+XyC+9WLgMfd/bnoh7evwsJCLyoq2n9BEemRKqpr+WBzBSs37gxem3ayZusudocdrCC4hzs6J+hQNjasSTfWqodkJqvDlfQpZvaWuxe2tq4jHdt2A78FfmtmWcB5BD3WY5LERSQ+uDubd1Y3S9YrN+1s+t4xBF9jOnR4JucVjmTs4PSgVp2bzohBqSRE8atVIr1Fp24SufsOgg5mC6MTjojEo9r6BtZs3c3KTeV7E/bGneyo3DvMwpicNCaNCHpETxwxgInDBzJ0gGrVIp9G7+zpISJR01pz+KotFdSEX3VKTuzHhGGZnHLYMA4dPoCJwwcwYfiAXtuxTCSW9F8lIq1ydzaVVzerWa/ctJOPtzdvDp80YgCXzRoT1q4HUJCbrpGqRLqJkriIUFvfwL+27trn/nVZRHN4QW46h+cN5PzpI5k4fAATRwxQJzORGFMSF+ljKqpreX9TBSs3ljcl6w8372r6Gldjc/iphw1rStbjh6k5XKQn0n+lSC/Vqebwo9UcLhKPlMRF4lxFdS1bdlazqTx4fbi5Qs3hIn2EkrhID1Xf4GzbtYfNYXLesrOazTur2VIe/GycjnxICqg5XKQv0X+1SAxU1tSxuTEZl7dMznvYUl7N1l17mj0XHIKhMYcOSGHogGQmDMvkuEMGM2xACsMGpjT9zBvU/shbItJ7KImLdKGGBqd0d01Qa26ZpCOmI8esbpSZktiUiMcNyWXYgBSGhsl5+MAUhg5IISc9iX56kpmIhJTERTqoura+WSJuvA/duGzLzj18UlFNbX3z2nM/gyGZQUIeOzidWQflNCXnyESdruZuEekkfWqIAHX1DWyp2MOGHVWU7Khkw44qNpRVNbsXHdlJrFFaUkKQiAekMLMguykhD41o4s7NSFLztohEhZK49Ak1dQ1sKq+iZEdVkKjL9k3WLe8/52YkMWxgCvlZqUwbndXUpN2YnIcOTCEzOVG9u0UkZqKaxM3sFOAnBOOJ3+/ud7VR7hzgMWC6u2ucUem0qpp6NpRVUrIjTNRlVXtr1WVVfFKxh8hRd81g2ICgE1jh6CzyslLJG5RGXlYq+Vmp5A1KJaV/QuzekIhIB0QtiZtZAnAPcBJQAiw3s6XuvrJFuUzgi8Ab0YpF4t/O6towKVexIUzMkcm6dHdNs/KJ/YwRg4Jk/Nlxg5sSc15WKvmD0hg2MIWkRDVxi0h8i2ZNfAaw2t3XAJjZEmAesLJFuW8D/w/4ShRjkR7M3dm+uyai9lzVlKQba9Ite3MnJ/YLa81pTBoxkPyIGnReVipDMlM0HrWI9HrRTOJ5wPqI+RJgZmQBMzsSGOnufzIzJfFebGvFHj7evrtFU/fe6ara5g8syUxObGranlmQ3dTcnZ8VJOmc9CTdixaRPi9mHdvMrB/wQ2BBB8peBVwFMGrUqOgGJl2mvsF58YNPeOi1Yl75aFuzddnpSeQNSuXgwRnMPmRwmKRTm2rXA1P7xyZoEZE4Es0kvgEYGTGfHy5rlAkcBrwU1qiGAUvNbG7Lzm3uvhBYCFBYWNi8C7H0OGWVNTxatJ5fv76O9durGDYghZtPPIQjRg4kP0zUaUn6YoSIyKcVzU/S5cA4MysgSN4XAF9oXOnu5UBu47yZvQR8Wb3T49fKjTt5aFkxT7y7gT11DcwsyOa2Uw/l5IlD9T1pEZEoiFoSd/c6M7seeJbgK2YPuPsKM7sTKHL3pdE6tnSf2voGnl2xmYeWFbO8eAcp/ftx9pH5XHLUaA4dPiDW4YmI9GpRbdN096eAp1os+2YbZWdHMxbpWp9UVLPkzfUsfmMdW3buYVR2Gt84/VDOmzaSgWm6ny0i0h10Y1I6zN15Z30Zi5YV86d/bqK23jn2kMF89+zRHHfIEH2lS0SkmymJy35V19bzx39sYtFrxfyjpJyM5EQunDmaS44azdjBGbEOT0Skz1ISlzZtLKviN6+vY8ny9WzfXcPBQzL49rxJnHVkPhkacUtEJOb0SSzNuDuvr9nOQ8uKeW7lZgBOPHQol84aw6yDcvSAFRGRHkRJXACorKnj8Xc2sGjZOlZtqWBQWn+uOvYgLpw5ipHZabEOT0REWqEk3scVb9vNr19fx6NF66mormPSiAF879wjmDt5hEbxEhHp4ZTE+6CGBuevH21l0bJiXvpwKwlmnHb4cC6dNZojR2WpyVxEJE4oifchO6tr+V1RCb9+rZji0koGZybzxRPG8YUZoxgyICXW4YmISCcpifcBH26p4KFlxTz+zgYqa+qZNjqLL508nlMmDdOY2iIicUxJvJeqq2/g+fc/4aFlxby2ppSkxH7MmzyCS2eN4bC8gbEOT0REuoCSeC+zfXcNS5Z/zOLXP2ZDWRV5g1K59ZQJnD99JNnpSbEOT0REupCSeC/xz5JyHnqtmKV/30hNXQNHH5zDN8+cyImHDtXjUEVEeikl8ThWU9fA0+9t4qFlxbz9cRlpSQmcXziSS44azbihmbEOT0REokxJPA5t2VnN4jc+5rdvfMy2XXsoyE3nW2dO5Jxp+QxI0QhiIiJ9RZ9O4o8uX8+tf/hHrMPoNHcwgznjh3DprDF89uBc+qnJXESkz4lqEjezU4CfAAnA/e5+V4v11wDXAfXALuAqd18ZzZgiTRwxgBvmHNxdh+syyf0TOOOI4YzOSY91KCJygGpraykpKaG6ujrWoUgPkZKSQn5+Pv37d7xF1dw9KsGYWQLwIXASUAIsB+ZHJmkzG+DuO8PpucB/uPsp7e23sLDQi4qKohKziEh3Wbt2LZmZmeTkaGAhCQafKi0tpaKigoKCgmbrzOwtdy9sbbtoPuljBrDa3de4ew2wBJgXWaAxgYfSgehcUYiI9DDV1dVK4NLEzMjJyel0y0w0m9PzgPUR8yXAzJaFzOw64EtAEnB8azsys6uAqwBGjRrV5YGKiMSCErhEOpC/h5g/c9Pd73H3g4BbgblLSRgAACAASURBVG+0UWahuxe6e+HgwYO7N0ARkV6otLSUKVOmMGXKFIYNG0ZeXl7TfE1NTbvbFhUVceONN+73GLNmzeqqcAG46aabyMvLo6GhoUv3G8+iWRPfAIyMmM8Pl7VlCXBvFOMREZFQTk4O7777LgB33HEHGRkZfPnLX25aX1dXR2Ji6ymisLCQwsJWb9E2s2zZsq4JFmhoaODxxx9n5MiR/PWvf2XOnDldtu9I7b3vniiaNfHlwDgzKzCzJOACYGlkATMbFzF7OvBRFOMREZF2LFiwgGuuuYaZM2dyyy238Oabb3LUUUcxdepUZs2axapVqwB46aWXOOOMM4DgAuDyyy9n9uzZjB07lrvvvrtpfxkZGU3lZ8+ezbnnnsuECRO48MILaexU/dRTTzFhwgSmTZvGjTfe2LTfll566SUmTZrEtddey8MPP9y0fMuWLZx11llMnjyZyZMnN104LFq0iCOOOILJkydz8cUXN72/xx57rNX4PvvZzzJ37lwmTpwIwOc+9zmmTZvGpEmTWLhwYdM2zzzzDEceeSSTJ0/mhBNOoKGhgXHjxrF161YguNg4+OCDm+ajLWqXG+5eZ2bXA88SfMXsAXdfYWZ3AkXuvhS43sxOBGqBHcCl0YpHRKSn+q8nV7By4879F+yEiSMG8K0zJ3V6u5KSEpYtW0ZCQgI7d+7klVdeITExkeeff56vfe1r/P73v99nmw8++IAXX3yRiooKxo8fz7XXXrvP16TeeecdVqxYwYgRIzj66KN59dVXKSws5Oqrr+bll1+moKCA+fPntxnXww8/zPz585k3bx5f+9rXqK2tpX///tx4440cd9xxPP7449TX17Nr1y5WrFjBf//3f7Ns2TJyc3PZvn37ft/322+/zXvvvdfUM/yBBx4gOzubqqoqpk+fzjnnnENDQwNXXnllU7zbt2+nX79+XHTRRSxevJibbrqJ559/nsmTJ9Ndt36j2mbg7k8BT7VY9s2I6S9G8/giItI55513HgkJCQCUl5dz6aWX8tFHH2Fm1NbWtrrN6aefTnJyMsnJyQwZMoQtW7aQn5/frMyMGTOalk2ZMoXi4mIyMjIYO3ZsU+KcP39+s1pvo5qaGp566il++MMfkpmZycyZM3n22Wc544wzeOGFF1i0aBEACQkJDBw4kEWLFnHeeeeRm5sLQHZ29n7f94wZM5p9tevuu+/m8ccfB2D9+vV89NFHbN26lWOPPbapXON+L7/8cubNm8dNN93EAw88wGWXXbbf43WV+Gn4FxHppQ6kxhwt6el7HyJ1++23M2fOHB5//HGKi4uZPXt2q9skJyc3TSckJFBXV3dAZdry7LPPUlZWxuGHHw5AZWUlqampbTa9tyUxMbGpU1xDQ0OzDnyR7/ull17i+eef57XXXiMtLY3Zs2e3+9WvkSNHMnToUF544QXefPNNFi9e3Km4Po2Y904XEZGeqby8nLy8PAAefPDBLt//+PHjWbNmDcXFxQA88sgjrZZ7+OGHuf/++ykuLqa4uJi1a9fy5z//mcrKSk444QTuvTfoE11fX095eTnHH388v/vd7ygtLQVoak4fM2YMb731FgBLly5ts2WhvLycrKws0tLS+OCDD3j99dcB+MxnPsPLL7/M2rVrm+0X4IorruCiiy5q1pLRHZTERUSkVbfccgu33XYbU6dO7VTNuaNSU1P5+c9/zimnnMK0adPIzMxk4MCBzcpUVlbyzDPPcPrppzctS09P55hjjuHJJ5/kJz/5CS+++CKHH34406ZNY+XKlUyaNImvf/3rHHfccUyePJkvfelLAFx55ZX89a9/ZfLkybz22mvNat+RTjnlFOrq6jj00EP56le/ymc+8xkABg8ezMKFCzn77LOZPHky559/ftM2c+fOZdeuXd3alA5RfOxqtOixqyLSG7z//vsceuihsQ4j5nbt2kVGRgbuznXXXce4ceO4+eabYx1WpxUVFXHzzTfzyiuvfKr9tPZ3EavHroqIiLTrF7/4BVOmTGHSpEmUl5dz9dVXxzqkTrvrrrs455xz+O53v9vtx1ZNXEQkBlQTl9aoJi4iItJHKImLiIjEKSVxERGROKUkLiIiEqeUxEVE+qA5c+bw7LPPNlv24x//mGuvvbbNbWbPnk1jx+LTTjuNsrKyfcrccccd/OAHP2j32E888QQrV65smv/m7bfz/LPPQG0V7NkFVWWwuxR2bYGKzbDrE9i9FSpLoWoHVJVD9c6gbE1lsF3dHqivhYY6bvriF/vMkKV67KqISB80f/58lixZwr/92781LVuyZAnf+973OrT9U089te/ChgZoqA+S6Z6KYLqhLvjpdU3zTyxZxBknHcfE7Abweu689uxg+60ffOr31dDQwOO/f5SRQ3P56x8eYM4xM8H6ARb8tH5gkdPtzNP2urr6BhL799+7HAvWdTPVxEVaamiAnRvh4zeg9F/BB5JIL3Puuefypz/9qen54cXFxWzcuJHPHnMM115zDYXTpjFp4kS+9fWvBrXf3dugviaoFZetY8yofLategM+eZ/vfPVGDhk7mmM+M41V/1gOuz+B0tX84mf/H9OPPo7JMz/LOfMvoXL7Zpa99jpLn32Br9z5A6ac9Hn+tWUXC75yF4+98A5kjeEvf1/P1NMWcPjJF3P51+9mT/YEGHY4Y2adxbfufYwjT7+Mw0++iA+2NUD2QZBVAINGw6BRMDCfl/5ezKSJE7n2qn/n4T++CCkDISmDLTt2cdZlNzJ5zlwmH3cmy15/E+qqWPSbxRwx60QmzzqBiy+7Cio2seDyK3ls8YNQ/jGUrSMjdwRs/xcvPfkwn/3sMcw9/ZRgyNItK/jcaScxbfIkJk04mIXfvx02/QM+eb/bhixVTVz6poYGqNgYJOnta1q81kJd1d6ylgCDRgYfGNlj975yDgo+PBKTYvc+pHd4+quw+Z9dsKOI534MnQQnfRu8IeK1t2acnVDPjKmH8/Qjv2LeqXNYcv99fP70Odjmf/CdGy4gO+tq6uvrOeH8a/jHnKkcMfGQIIlXlUF1RdOx3nrvQ5YsfY53X/0LdQ3OkceezLSZR0POwZx98VVcefPt0C+Bb9z+TX75pze44YYbmDvvOc444wzOPffcINb+v4CUAVRbKguuuo6//OUvHHLIIVxyySXce9//ctNNNwGQO2QYb7/zLj//+c/5wd33cv/99+9zBh5+4hnmX7wgGLL029+nNn14MGTpNbdw3Emn8fhNN+0dsrSkhP/+6YPNhyzNyoLUrOB/fshEcA9q2jnjYMBG3n7vQ94repWC0SPBG3hg4X1kZw2kqnI30+eczjnnnEeD13TbkKVRTeJmdgrwE4LxxO9397tarP8ScAVQB2wFLnf3ddGMSfqQhnooL2klSYeJun7P3rIJScEVfc5BcNDxkF0AA0dB5bagfGOyL1kOeyLGfbZ+MDA/TOwH7Zvg+6d0//uWnq2hHmorg591e4Lk2lAbNDc7NCXipgdxtTIfWa7ZfEQSryyFre+3HYf1Y/7ck1jyh6XMO/V4lvzfM/zyp9+HjCE8+rvnWPir31BXX8+mzVtYuXkPR8yZBEkZMPgQGHYY9OsPOQfxytOvcda5nydt+MEAzJ13FvRPheRM3lv1Nt847wuUlZWxa9euZk33rVm1ahUFBQUccsghAFx66aXcc889TUn87LODZvdp06bxhz/8YZ/tu2zIUjPolwiJe0deIzkDktKDIUsPndK0+O7v37N3yNINm/jok8puHbI0aknczBKAe4CTgBJguZktdfeVEcXeAQrdvdLMrgW+B5y/795E2lBfB+XrW0/UO4qDmkOjxJQwwR4M405qnngHjIB+HRh5yB0qt8P2FjX40n/Be49BdXlEYQsTfMG+tfjsguCDTno+9yDpVpZGvLYHv+vayrBjVWXE9O69y2p2B52umqYroS4c0vLfHoVPwls1Uy9qP4Zm92QTWsz3g3799l22T5lwu36JTdPzLj2Im//rh7z9cQWVe+qYNvt01q5dyw9+upDly5eTlZXFggULqK5rCC50O2nBggU88cQTTJ48mQcffJCXXnqp0/uI1DicaVtDmfbFIUujWROfAax29zUAZrYEmAc0JXF3fzGi/OvAfv6S+6D6OihbB9s+gm0fBq/yEkhKh5RBwf2e1PBn0ytiPnUQ9E+LSYeLLlNfC2UfB7Xnlslzx7qgFtOof1qQJAePh/GnNk+emcODD7tPwwzSc4LXyBn7rq/c3nqcK/8PqrY3Lzsgb29Cb5bkC4Lfr0RHbXWLhBwm5baWVW3fm3jbkpgaXJQlpQd/g0lp0D8dMoaE8+nB+qbptLDJdlTrSTkyOUexw1RGRgZz5szh8ssvZ/78+QDs3LmT9PR0Bg4cyJYtW3j66afbHEcc4Nhjj2XBggXcdttt1NXV8eSTTzY9/7yiooLhw4dTW1vL4sWLm4Y1zczMpKKiYp99jR8/nuLiYlavXs3BBx/Mr3/9a4477rgOv5/GIUsb38vu3bspKChoNmTpTRHN6ccffzxnnXUWX/rSl8jJyWH79u1kZ2c3DVn6+c9//oCHLP2P//gP1q5d29Sc3lgbbxyy9OKLL+6SIUujmcTzgPUR8yXAzHbK/zvwdBTj6dmqd0LpR82T9baPghpeZJJKHxz84+/6JKgJVJdBza72990vcd/kvk/yH7T3Z8vl3XHPt64mTNSt1HDLPg7u5TVKyggS3dBJcOjc5jXczGGxvWBJyw5e+dP2XVe1I0zwLVoMVj0dfH0mUubwiAQf2VRfAMmZ3fNe4kFdTZBkW03ALZeH87W7295fahak5QSvQSNhxOS982k5kJodTmcH/x/904LXgVwcvv9+sK8Ymz9/PmeddRZLliwBYPLkyUydOpUJEyYwcuRIjj766Ha3P/LIIzn//POZPHkyQ4YMYfr06U3rvv3tbzNz5kwGDx7MzJkzmxL3BRdcwJVXXsndd9/NY4891lQ+JSWFX/3qV5x33nnU1dUxffp0rrnmmg69j8YhS++7776mZS2HLL3qqqv45S9/SUJCAvfeey9HHXVU05ClCQkJTJ06lQcffJArr7ySefPmMXnyZE455ZR2hyy97777OPTQQxk/fnyrQ5Y2NDQwZMgQ/vznPwPBkKWXXXZZlw1ZGrUBUMzsXOAUd78inL8YmOnu17dS9iLgeuA4d9/TyvqrgKsARo0aNW3duji9bd7QADs37E3Qjcm6dDVUbNpbzhKCD+zcQyD34PDnIUEzcFr2vvutrwvu01btCBN7mNwbp6sipltbV7/PKW8uMXU/ib+d5SkD9zZT1+0JmrhbJunta4ImcY/4TmdSJuSMpdV7zemD47tloTXV5a0n+O1rgu/KRkofEpyH1mrxKQNiE39XqK8L/oYba78dqSlH9k9oKXlAeFGV0+LV2rKc4O82ofv6+moAlL5pf0OWdnYAlGj+xW4ARkbM54fLmjGzE4Gv00YCB3D3hcBCCEYx6/pQu1htVZCYt30I21Y3T9a1lXvLJQ+E3HEwdk7wszFZZ43pXO03IXFvDfCA4q1uI/GXtZ74d30SXIQ0zkfWkluTPCBoStz1Cc063iQPDBJ1/nQ44vzmiTotp/cl6vakDIQRU4JXS3t2tZ7c//UCvLupedm0nPhrineCZFy974NDmvRPb56Asw9qPymnZulbA9Lj3HXXXdx7771dci+8UTRr4onAh8AJBMl7OfAFd18RUWYq8BhBjf2jjuy3xwxF6h40gUY2fTdOl61nb7KyoFmuMUFHJuveUKN0D5rz91fj31Ox9x5wYy0yNSv+33+s1ewOWjcaWzR2rA1aPOJNUkY7STm7V3YCVE1cWtNjauLuXmdm1wPPEnzF7AF3X2FmdwJF7r4U+D6QAfzOgg/zj919brRiOiD1tUEz5z7J+iPYE9ETuX9a0NydPwOmXLQ3Wecc1Cs/gJqYBfdokzODntjSvZLSg74BQyfFOhIRiYGo3gBy96eAp1os+2bE9InRPH6nVO1o0aksbAbfsTZ4OEKjzOFBgj7ivOY168wRn77ns4j0Ke6OqTVKQgfSMt63n9j24XPw6o+DZB3ZOzghKbjnNuRQmDhvbweznHHx3XFIRHqMlJQUSktLycnJUSIX3J3S0lJSUjr3gKi+ncTNgh7R408NEnRjzXrQ6G7tpSoifU9+fj4lJSWf+tnZ0nukpKSQn9+525J9O1ONOyl4iYh0s/79+zc9llPkQOkmroiISJxSEhcREYlTSuIiIiJxKmoPe4kWM9sKdOVzV3OBbV24P2mbznX30HnuHjrP3UPnGUa7e6sDj8ddEu9qZlbU1pNwpGvpXHcPnefuofPcPXSe26fmdBERkTilJC4iIhKnlMTD0dGkW+hcdw+d5+6h89w9dJ7b0efviYuIiMQr1cRFRETiVJ9O4mZ2ipmtMrPVZvbVWMfTG5nZSDN70cxWmtkKM/tirGPqzcwswczeMbM/xjqW3srMBpnZY2b2gZm9b2ZHxTqm3srMbg4/N94zs4fNrHOjg/QBfTaJm1kCcA9wKjARmG9mE2MbVa9UB/ynu08EPgNcp/McVV8E3o91EL3cT4Bn3H0CMBmd76gwszzgRqDQ3Q8DEoALYhtVz9NnkzgwA1jt7mvcvQZYAsyLcUy9jrtvcve3w+kKgg+8vNhG1TuZWT5wOnB/rGPprcxsIHAs8EsAd69x97LYRtWrJQKpZpYIpAEbYxxPj9OXk3gesD5ivgQll6gyszHAVOCN2EbSa/0YuAVoiHUgvVgBsBX4VXjb4n4zS491UL2Ru28AfgB8DGwCyt39udhG1fP05SQu3cjMMoDfAze5+85Yx9PbmNkZwCfu/lasY+nlEoEjgXvdfSqwG1B/migwsyyC1tECYASQbmYXxTaqnqcvJ/ENwMiI+fxwmXQxM+tPkMAXu/sfYh1PL3U0MNfMigluDR1vZr+JbUi9UglQ4u6NrUmPESR16XonAmvdfau71wJ/AGbFOKYepy8n8eXAODMrMLMkgg4TS2McU69jZkZw//B9d/9hrOPprdz9NnfPd/cxBH/LL7i7ai1dzN03A+vNbHy46ARgZQxD6s0+Bj5jZmnh58gJqBPhPhJjHUCsuHudmV0PPEvQ6/EBd18R47B6o6OBi4F/mtm74bKvuftTMYxJ5NO4AVgcXvyvAS6LcTy9kru/YWaPAW8TfMvlHfT0tn3oiW0iIiJxqi83p4uIiMQ1JXEREZE4pSQuIiISp5TERURE4pSSuIiISJxSEhcREYlTSuIiIiJxSklcpAPM7Gkzu7Sry8aSmRWb2YlR2O9LZnZFOH2hmbU5aEVk2QM4zigz2xUOKyzSJymJS68VfsA3vhrMrCpi/sLO7MvdT3X3h7q6bE9kZl81s5dbWZ5rZjVmdlhH9+Xui9395C6Kq9lFh7t/7O4Z7l7fFftvcSw3s4O7er8iXU1JXHqt8AM+w90zCJ7DfGbEssWN5cKximWv3wCzzKygxfILgH+6+3sxiElEWqEkLn2Omc02sxIzu9XMNhOMDZ1lZn80s61mtiOczo/YJrKJeIGZ/c3MfhCWXWtmpx5g2QIze9nMKszseTO7p63RxzoY47fN7NVwf8+ZWW7E+ovNbJ2ZlZrZ19s6P+5eArxA8Mz7SJcAi/YXR4uYF5jZ3yLmTzKzD8ys3Mx+BljEuoPM7IUwvm1mttjMBoXrfg2MAp4MW1JuMbMxYY05MSwzwsyWmtl2M1ttZldG7PsOM3vUzBaF52aFmRW2dQ7aYmYDw31sDc/lN8ysX7juYDP7a/jetpnZI+FyM7MfmdknZrbTzP7ZmdYMkfYoiUtfNQzIBkYDVxH8L/wqnB8FVAE/a2f7mcAqIBf4HvBLM7MDKPtb4E0gB7iDfRNnpI7E+AWCATmGAEnAlwHMbCJwb7j/EeHxWk28oYciY7Fg1K4pYbydPVeN+8glGE7yGwTn4l8EA+Q0FQG+G8Z3KMFQwXcAuPvFNG9N+V4rh1hCMFToCOBc4H/M7PiI9XPDMoMIRizcb8yt+CkwEBgLHEdwYdM4AMq3geeALIJz+9Nw+cnAscAh4bafB0oP4Ngi+1ASl76qAfiWu+9x9yp3L3X337t7pbtXAN8h+JBuyzp3/0V4P/YhYDgwtDNlzWwUMB34prvXuPvfaGc43A7G+Ct3/9Ddq4BHCRIvBEntj+7+srvvAW4Pz0FbHg9jbBy/+RLg6XBs586eq0anASvc/bFwfOgfA5sj3t9qd/9z+DvZCvywg/vFzEYSXBDc6u7V7v4ucH8Yd6O/uftT4e/h18Dkjuw74hgJBLcUbnP3CncvBv4/9l7s1BJc2IwIY/hbxPJMYALBoFPvu/umzhxbpC1K4tJXbXX36sYZC8Ys/t+wiXQn8DIwyNru+RyZfCrDyYxOlh0BbI9YBrC+rYA7GOPmiOnKiJhGRO7b3XfTTm0wjOl3wCVhq8GFwKJOxNGaljF45LyZDTWzJWa2Idzvbwhq7B3ReC4rIpatA/Ii5luemxTrXH+IXKB/uN/WjnELQWvCm2Fz/eUA7v4CQa3/HuATM1toZgM6cVyRNimJS1/Vcgze/wTGAzPdfQBB8ydE3LONgk1AtpmlRSwb2U75TxPjpsh9h8fM2c82DxE0/Z5EUJN88lPG0TIGo/n7/R+C38vh4X4varHP9sZN3khwLjMjlo0CNuwnps7Yxt7a9j7HcPfN7n6lu48ArgZ+bmEPd3e/292nARMJmtW/0oVxSR+mJC4SyCS4t1tmZtnAt6J9QHdfBxQBd5hZkpkdBZwZpRgfA84ws2PMLAm4k/3//78ClAELgSXuXvMp4/gTMMnMzg5rwDcS9E1olAnsAsrNLI99E90WgnvR+3D39cAy4LtmlmJmRwD/TlCbP1BJ4b5SzCwlXPYo8B0zyzSz0cCXGo9hZudFdPDbQXDR0WBm081sppn1B3YD1bR/K0Okw5TERQI/BlIJaluvA89003EvBI4iaNr+b+ARYE8bZQ84RndfAVxH0DFtE0GSKdnPNk7QhD46/Pmp4nD3bcB5wF0E73cc8GpEkf8CjgTKCRL+H1rs4rvAN8yszMy+3Moh5gNjCGrljxP0eXi+I7G1YQXBxUrj6zLgBoJEvAb4G8H5fCAsPx14w8x2EfRt+KK7rwEGAL8gOOfrCN779z9FXCJNLPg/FZGeIPxa0gfuHvWWABGJf6qJi8RQ2NR6kJn1M7NTgHnAE7GOS0Tig55UJRJbwwiajXMImrevdfd3YhuSiMQLNaeLiIjEKTWni4iIxCklcRERkTgVd/fEc3NzfcyYMbEOQ0REpFu89dZb29x9cGvr4i6JjxkzhqKioliHISIi0i3MbF1b69ScLiIiEqeUxEVEROKUkriIiEicirt74iIisn+1tbWUlJRQXV29/8LSI6SkpJCfn0///v07vI2SuIhIL1RSUkJmZiZjxowhGPVVejJ3p7S0lJKSEgoKCjq8nZrTRUR6oerqanJycpTA44SZkZOT0+mWEyVxEZFeSgk8vhzI70tJXEREulxpaSlTpkxhypQpDBs2jLy8vKb5mpqadrctKirixhtv3O8xZs2a1SWxvvTSS5xxxhldsq/upnviIiLS5XJycnj33XcBuOOOO8jIyODLX/5y0/q6ujoSE1tPQYWFhRQWFu73GMuWLeuaYOOYauIiItItFixYwDXXXMPMmTO55ZZbePPNNznqqKOYOnUqs2bNYtWqVUDzmvEdd9zB5ZdfzuzZsxk7dix333130/4yMjKays+ePZtzzz2XCRMmcOGFF9I4QudTTz3FhAkTmDZtGjfeeGOnatwPP/wwhx9+OIcddhi33norAPX19SxYsIDDDjuMww8/nB/96EcA3H333UycOJEjjjiCCy644NOfrA7qlpq4mT0AnAF84u6Hhcu+D5wJ1AD/Ai5z97LuiEdERGKjpKSEZcuWkZCQwM6dO3nllVdITEzk+eef52tf+xq///3v99nmgw8+4MUXX6SiooLx48dz7bXX7vM1rHfeeYcVK1YwYsQIjj76aF599VUKCwu5+uqrefnllykoKGD+/PkdjnPjxo3ceuutvPXWW2RlZXHyySfzxBNPMHLkSDZs2MB7770HQFlZkLbuuusu1q5dS3JyctOy7tBdzekPAj8DFkUs+zNwm7vXmdn/A24Dbu2meERE+oz/enIFKzfu7NJ9ThwxgG+dOanT25133nkkJCQAUF5ezqWXXspHH32EmVFbW9vqNqeffjrJyckkJyczZMgQtmzZQn5+frMyM2bMaFo2ZcoUiouLycjIYOzYsU1f2Zo/fz4LFy7sUJzLly9n9uzZDB4cjDty4YUX8vLLL3P77bezZs0abrjhBk4//XROPvlkAI444gguvPBCPve5z/G5z32u0+flQHVLc7q7vwxsb7HsOXevC2dfB/L32VBERHqV9PT0punbb7+dOXPm8N577/Hkk0+2+fWq5OTkpumEhATq6uoOqExXyMrK4u9//zuzZ8/mvvvu44orrgDgT3/6E9dddx1vv/0206dPj9rxW+opHdsuBx5pa6WZXQVcBTBq1KjuiklEpFc4kBpzdygvLycvLw+ABx98sMv3P378eNasWUNxcTFjxozhkUfaTDP7mDFjBjfeeCPbtm0jKyuLhx9+mBtuuIFt27aRlJTEOeecw/jx47noootoaGhg/fr1zJkzh2OOOYYlS5awa9cuBg0a1OXvqaWYJ3Ez+zpQByxuq4y7///t3XuYXHWd5/H3t6o7d5bLENERZsgoN7mESyMOeAHBEY2bLIgKKw6BXVGWEWFnQdkHjasy4sq4jKuiEYZBZYiKyKrAeAmKujqaEEICQUaULAYQAjOEcEu6u777R53qrm46SVfS3aer+/16nn7qnN+5fbsI/fmd+2JgMUBXV1eOUWmSpFF00UUXccYZZ/Dxj3+cefPmjfj6p0+fzuc//3lOGPBW+gAAGTtJREFUPPFEZs6cyZFHHrnFeZcuXTrgEP03vvENLrvsMo477jgyk3nz5rFgwQLuuusuzjzzTGq1GgCf+MQn6O3t5fTTT2fDhg1kJuedd96YBDhANK7gG/UNRewNfLdxYVvRthB4D3B8Zj47nPV0dXWl7xOXpK279957OeCAA8ouo3RPP/00s2bNIjM599xz2WeffbjgggvKLmuLhvrvFhF3ZOaQ99yVdotZRJwIXATMH26AS5LUii996UsceuihHHjggWzYsIH3vOc9ZZc0osbqFrPrgWOB3SNiHbCI+tXoU4EfFI+a++fMfO9Y1CNJmhwuuOCCcb3nvaPGJMQzc6ib864ei21LkjRR+cQ2SZLalCEuSVKbMsQlSWpThrgkacQdd9xxfO973xvQdsUVV3DOOedscZljjz2Wxi3Eb37zm4d8BvlHPvIRLr/88q1u+6abbmLNmjV94x/+8If54Q9/2Er5QxqPryw1xCVJI+60005jyZIlA9qWLFky7JeQ3HLLLdv9wJTBIf7Rj36UE044YbvWNd4Z4pKkEXfKKadw8803s3nzZgDWrl3Lww8/zGte8xrOOeccurq6OPDAA1m0aNGQy++99948/vjjAFx66aXsu+++vPrVr+57XSnU7wE/8sgjmTt3Lm9961t59tln+fnPf863v/1tLrzwQg499FB++9vfsnDhQm644Qag/mS2ww47jIMPPpizzjqLTZs29W1v0aJFHH744Rx88MH8+te/HvbvWuYrSw1xSdKI22233XjlK1/JrbfeCtT3wt/+9rcTEVx66aUsX76cVatWcfvtt7Nq1aotrueOO+5gyZIlrFy5kltuuYVly5b1TTv55JNZtmwZd911FwcccABXX301Rx99NPPnz+dTn/oUK1eu5GUve1nf/M8//zwLFy7ka1/7GqtXr6anp4crr7yyb/ruu+/OihUrOOecc7Z5yL6h8crS2267jZUrV7Js2TJuuukmVq5c2ffK0tWrV3PmmWcC9VeW3nnnnaxatYovfOELLX2nQyn92emSpFF26wfhD6tHdp0vPhjedNlWZ2kcUl+wYAFLlizh6qvrjwf5+te/zuLFi+np6eGRRx5hzZo1HHLIIUOu46c//SknnXQSM2bMAGD+/Pl90+6++24uueQSnnzySZ5++mne+MY3brWe++67jzlz5rDvvvsCcMYZZ/C5z32O888/H6h3CgCOOOIIbrzxxmF8CeW/stQ9cUnSqFiwYAFLly5lxYoVPPvssxxxxBE88MADXH755SxdupRVq1Yxb968Lb6CdFsWLlzIZz/7WVavXs2iRYu2ez0NjdeZjsSrTMfqlaXuiUvSRLeNPebRMmvWLI477jjOOuusvgvannrqKWbOnMnOO+/Mo48+yq233sqxxx67xXW89rWvZeHChVx88cX09PTwne98p+/55xs3buQlL3kJ3d3dXHfddX2vNd1pp53YuHHjC9a13377sXbtWu6//35e/vKX85WvfIXXve51O/Q7lv3KUkNckjRqTjvtNE466aS+K9Xnzp3LYYcdxv77789ee+3FMcccs9XlDz/8cN7xjncwd+5cXvSiFw14nejHPvYxjjrqKGbPns1RRx3VF9ynnnoq7373u/nMZz7Td0EbwLRp07jmmmt429veRk9PD0ceeSTvfW9rr+wYb68sHbNXkY4UX0UqSdvmq0jbU9u8ilSSJO0YQ1ySpDZliEuS1KYMcUmaoNrtmqfJbnv+exnikjQBTZs2jSeeeMIgbxOZyRNPPMG0adNaWs5bzCRpAtpzzz1Zt24d69evL7sUDdO0adMG3L42HIa4JE1AnZ2dzJkzp+wyNMo8nC5JUpsyxCVJalNjFuIR8fcR8VhE3N3UtltE/CAiflN87jpW9UiS1O7Gck/8H4ATB7V9EFiamfsAS4txSZI0DGMW4pn5E+BfBzUvAK4thq8FdvzlqpIkTRJlnxPfIzMfKYb/AOxRZjGSJLWTskO8T9afSDDkUwki4uyIWB4Ry73nUZKkurJD/NGIeAlA8fnYUDNl5uLM7MrMrtmzZ49pgZIkjVdlh/i3gTOK4TOA/1NiLZIktZWxvMXseuAXwH4RsS4i/hNwGfCGiPgNcEIxLkmShmHMHruamadtYdLxY1WDJEkTSdmH0yVJ0nYyxCVJalOGuCRJbcoQlySpTRnikiS1KUNckqQ2ZYhLktSmDHFJktqUIS5JUpsyxCVJalOGuCRJbcoQlySpTRnikiS1KUNckqQ2ZYhLktSmWgrxiHhfROw6WsVIkqTha3VPfA9gWUR8PSJOjIgYjaIkSdK2tRTimXkJsA9wNbAQ+E1E/E1EvGwUapMkSVvR8jnxzEzgD8VPD7ArcENE/M8Rrk2SJG1FRyszR8T7gb8EHgeuAi7MzO6IqAC/AS4a+RIlSdJQWgpxYDfg5Mz8f82NmVmLiLeMXFmSJGlbWj0nvgj4o4g4r7hS/fCmafduTwERcUFE3BMRd0fE9RExbXvWI0nSZNPqLWYfAq4F/gjYHbgmIi7Z3o1HxEuB84CuzDwIqAKnbu/6JEmaTFo9nH46MDcznweIiMuAlcDHd7CG6RHRDcwAHt6BdUmSNGm0enX6w0Dz4e6pwEPbu/HMfAi4HHgQeATYkJnf3971SZI0mbQa4huAeyLiHyLiGuBu4MmI+ExEfKbVjRdPf1sAzAH+GJgZEacPMd/ZEbE8IpavX7++1c1IkjQhtXo4/VvFT8OPd3D7JwAPZOZ6gIi4ETga+GrzTJm5GFgM0NXVlTu4TUmSJoSWQjwzr42IKcC+RdN9mdm9A9t/EHhVRMwAngOOB5bvwPokSZo0Wn3Yy7HUr05fCwSwV0SckZk/2Z6NZ+YvI+IGYAX1p7/dSbHHLUmStq7Vw+l/C/xFZt4HEBH7AtcDR2xvAcW954u2d3lJkiarVi9s62wEOEBm/gvQObIlSZKk4Wh1T/yOiLiK/gvP3onnsCVJKkWrIf5e4FzqT1kD+Cnw+RGtSJIkDcuwQzwiqsBdmbk/8OnRK0mSJA3HsM+JZ2YvcF9E/Mko1iNJkoap1cPpu1J/YtuvgGcajZk5f0SrkiRJ29RqiH9oVKqQJEktazXE35yZH2huiIhPArePXEmSJGk4Wr1P/A1DtL1pJAqRJEmtGdaeeEScA/wX4M8iYlXTpJ2An49GYZIkaeuGezj9H4FbgU8AH2xq35iZ/zriVUmSpG0aVohn5gbq7xI/rbhffI9i2VkRMSszHxzFGiVJ0hBafYvZXwEfAR4FakVzAoeMbFmSJGlbWr06/Xxgv8x8YjSKkSRJw9fq1em/p35YXZIklazVPfHfAT+OiJuBTY3GzPRZ6pIkjbFWQ/zB4mdK8SNJkkrSUohn5v8Y3BYRrXYEJEnSCBjWOfGI+FnT8FcGTf7ViFYkSZKGZbgXts1sGj5o0LQYoVokSVILhhviuYXhocYlSdIYGO757F0i4iTqob9LRJxctAew86hUJkmStmq4IX47ML9p+N83TfvJjhQQEbsAV1E/TJ/AWZn5ix1ZpyRJk8Fwn51+5ijW8HfAP2XmKRExBZgxituSJGnCKPX2sIjYGXgtsBAgMzcDm8usSZKkdtHqY1dH2hxgPXBNRNwZEVdFxMxtLSRJksoP8Q7gcODKzDwMeIaB7ysHICLOjojlEbF8/fr1Y12jJEnjUkshHhFvi4idiuFLIuLGiDh8B7a/DliXmb8sxm+gHuoDZObizOzKzK7Zs2fvwOYkSZo4Wt0T/1BmboyIVwMnAFcDV27vxjPzD8DvI2K/oul4YM32rk+SpMmk1RDvLT7nAYsz82Z2/EUo7wOui4hVwKHA3+zg+iRJmhRavTr9oYj4IvAG4JMRMZUdPK+emSuBrh1ZhyRJk1GrAfx24HvAGzPzSWA34MIRr0qSJG1Tq3viLwFuzsxNEXEscAjw5RGvSpIkbVOre+LfBHoj4uXAYmAv4B9HvCpJkrRNrYZ4LTN7gJOB/52ZF1LfO5ckSWOs1RDvjojTgL8Evlu0dY5sSZIkaThaDfEzgT8HLs3MByJiDvCVkS9LkiRtS0shnplrgP8GrI6Ig6g/be2To1KZJEnaqpauTi+uSL8WWAsEsFdEnJGZO/ROcUmS1LpWbzH7W+AvMvM+gIjYF7geOGKkC5MkSVvX6jnxzkaAA2Tmv+CFbZIklaLVPfE7IuIq4KvF+DuB5SNbkiRJGo5WQ/y9wLnAecX4T4HPj2hFkiRpWIYd4hFRBe7KzP2BT49eSZIkaTiGfU48M3uB+yLiT0axHkmSNEytHk7fFbgnIn4FPNNozMz5I1qVJEnaplZD/EOjUoUkSWrZsEK8eGvZHpl5+6D2VwOPjEZhkiRp64Z7TvwK4Kkh2jcU0yRJ0hgbbojvkZmrBzcWbXuPaEWSJGlYhhviu2xl2vSRKESSJLVmuCG+PCLePbgxIv4zcMfIliRJkoZjuFennw98KyLeSX9odwFTgJN2tIjiQTLLgYcy8y07uj5JkiaDYYV4Zj4KHB0RxwEHFc03Z+ZtI1TH+4F7gX83QuuTJGnCa+k+8cz8EfCjkSwgIvYE5gGXAv91JNctSdJE1uqrSEfDFcBFQK3sQiRJaielhnhEvAV4LDO3enFcRJwdEcsjYvn69evHqDpJksa3svfEjwHmR8RaYAnw+oj46uCZMnNxZnZlZtfs2bPHukZJksalUkM8My/OzD0zc2/gVOC2zDy9zJokSWoXZe+JS5Kk7dTqW8xGTWb+GPhxyWVIktQ23BOXJKlNGeKSJLUpQ1ySpDZliEuS1KYMcUmS2pQhLklSmzLEJUlqU4a4JEltyhCXJKlNGeKSJLUpQ1ySpDZliEuS1KYMcUmS2pQhLklSmzLEJUlqU4a4JEltyhCXJKlNGeKSJLUpQ1ySpDZliEuS1KYMcUmS2pQhLklSmyo1xCNir4j4UUSsiYh7IuL9ZdYjSVI76Sh5+z3AX2fmiojYCbgjIn6QmWtKrkuSpHGv1D3xzHwkM1cUwxuBe4GXllmTJEntYtycE4+IvYHDgF8OMe3siFgeEcvXr18/1qVJkjQujYsQj4hZwDeB8zPzqcHTM3NxZnZlZtfs2bPHvkBJksah0kM8IjqpB/h1mXlj2fVIktQuyr46PYCrgXsz89Nl1iJJUrspe0/8GOBdwOsjYmXx8+aSa5IkqS2UeotZZv4MiLK2/3/vf5wv/2ItUzqqdFaDqR0VplQrTOmo/3Q2hqsVpjaPF22dHRWmDnP+jkpQP/AgSdLIKPs+8VJtfL6HtY8/y+beGpt7av2fxXBvLUdsWxHUOwjNHYFG0A/qHDR/NjoCU/vmD6Z2VJneWWXalPrn9M4qM6ZUmdZZZfqUocerFTsQkjTRTOoQP/GgF3PiQS/e4vTeWtLdW2NTEezdg8O+OfQb05vm3+Yyvf3TG8s8u7mHJ58buN7Nvcnmnt6+ZbenbzGlo9IX+NOLgJ9RBHwj7Gc0TavPV2H6lI6m5SpM7+zo6xjUOxIVZhTz2FGQpLE1qUN8W6qVoFqph9p40tNb47nuXp7r7uX5zf3Dz27u4fnuXp5rtG3uKT7r488X8zzXXeO5zf3jTzyzuViut5i/3mFo1ZRqhWmdRaj3dQYqA44GVKL+E0HfeARUi/ZKhb55KgGVytDD1aifnqhEUK0wYLhSTKsWy9SHi3VEFOsZYrhpnmqlXldjuG+7leiro9pUb7UycNnGuqtNtTf/js3fRWO9nm6R1CpDvA11VCvsVK2w07TOUdtGT2+N53vqYd8X7kXA18O/t6kj0T/e3Bl4tpj3ue5e/u2ZbmqZ1DLprSWZ1IczqdUgG8NZDNfqw7VMak3DmRTz1Ycnkr5OQ3PnoKmjUW3qkDQ6GdWic9DcKap3PqNv2oDxStAx1HzFvB3V+rSOorPS/NmoZcC0Yt76OipUK/R91qcNbKtWKkPW1PgdBnbkmjtXxfSmzlI0Ta9GEIOWi0GdMztJmogMcQ2po1phVrXCrKnj959IZlPQF52BoYZ7s6nTUBs43NdpGLx8Usw7sENRH250Rvo7GY0OSK2Wg+ajf7iW9DbP0+iU1LJ/W8V6G9ttnqe5E9TYVvN2++dPehrjxc/mnlqx7iF+hmrPpLe3/tlTq9feM4LXiJShP9QbR24Y2EEYdFRkS9MbR1k6KsHUzipTqxWmdtavW5naUa1/dhYXuHYW48W0xvUt9fmrfde6NC83YL5iWmfVIzUa2vj9Cy1tQ+OQebW8GxwmnUaYNzoTzQFfGxT4zZ2C2hAdi/4ORK2pA9XfOWt0SJo7ZZn98/V32AYeqWme3reuWg7q9NG/7iGO+Aw1PQd15Hp6k009NTb19PL0ph6eeLpxTUwvm7prfdM29dR2+KhR48LYetD3dwymdDR1Ega0v7Bj0Lj7pqMadFQrdFaCzmK8s1q/g6azo0JnpdFWP5LSWa1fUNtRzNO426ajaG8sayejHIa4pGGrVIIpXsDYksaRkU09NTZ19/ZdxNoc8pu6a2zufWH4981XLDdgmWK5xvhTz3X3T+9uXCzbP+9oqwd70Fmp337bMVQnoWm8v5PQaK93LBqdjCnV/s5CtUJxGmao0zNQrTZO02z51M3g00BDnWJqPp1UrbzwtFHfqaWm00CVkv9/MMQlaRRFRF9QlXV6KrPeiejurdHTm3TXis/eGt29Sc/g8d4a3bXis2me7mKexrw9xTybi2V6ao11NOZpLNe/3p7i9M7z3TV6enuGXHdPrd6Bqa+//5TPeDX42pGdZ3Tysw+8fmy2PSZbkSSVJiKY1jn+7rRpRfOpka2enundynUetRq9NegpTuE0tw2YVpwuaT5F1Hf6aNBpo77TR9k/PKVj7B6GaohLksa9vmtgPJ0zQNnPTpckSdvJEJckqU0Z4pIktSlDXJKkNmWIS5LUpgxxSZLalCEuSVKbMsQlSWpThrgkSW3KEJckqU0Z4pIktanSQzwiToyI+yLi/oj4YNn1SJLULkoN8YioAp8D3gS8AjgtIl5RZk2SJLWLsvfEXwncn5m/y8zNwBJgQck1SZLUFsoO8ZcCv28aX1e0SZKkbWiL94lHxNnA2cXo0xFx3wiufnfg8RFcn7bM73ps+D2PDb/nseH3DH+6pQllh/hDwF5N43sWbQNk5mJg8WgUEBHLM7NrNNatgfyux4bf89jwex4bfs9bV/bh9GXAPhExJyKmAKcC3y65JkmS2kKpe+KZ2RMRfwV8D6gCf5+Z95RZkyRJ7aLsw+lk5i3ALSWWMCqH6TUkv+ux4fc8Nvyex4bf81ZEZpZdgyRJ2g5lnxOXJEnbaVKHuI98HX0RsVdE/Cgi1kTEPRHx/rJrmsgiohoRd0bEd8uuZaKKiF0i4oaI+HVE3BsRf152TRNVRFxQ/N24OyKuj4hpZdc03kzaEPeRr2OmB/jrzHwF8CrgXL/nUfV+4N6yi5jg/g74p8zcH5iL3/eoiIiXAucBXZl5EPWLn08tt6rxZ9KGOD7ydUxk5iOZuaIY3kj9D55P5RsFEbEnMA+4quxaJqqI2Bl4LXA1QGZuzswny61qQusApkdEBzADeLjkesadyRziPvJ1jEXE3sBhwC/LrWTCugK4CKiVXcgENgdYD1xTnLa4KiJmll3URJSZDwGXAw8CjwAbMvP75VY1/kzmENcYiohZwDeB8zPzqbLrmWgi4i3AY5l5R9m1THAdwOHAlZl5GPAM4PU0oyAidqV+dHQO8MfAzIg4vdyqxp/JHOLDeuSrdlxEdFIP8Osy88ay65mgjgHmR8Ra6qeGXh8RXy23pAlpHbAuMxtHk26gHuoaeScAD2Tm+szsBm4Eji65pnFnMoe4j3wdAxER1M8f3puZny67nokqMy/OzD0zc2/q/5Zvy0z3WkZYZv4B+H1E7Fc0HQ+sKbGkiexB4FURMaP4O3I8XkT4AqU/sa0sPvJ1zBwDvAtYHREri7b/XjypT2pH7wOuKzr/vwPOLLmeCSkzfxkRNwArqN/lcic+ve0FfGKbJEltajIfTpckqa0Z4pIktSlDXJKkNmWIS5LUpgxxSZLalCEuacRExLG+QU0aO4a4JEltyhCXJqGIOD0ifhURKyPii8V7yJ+OiP9VvL95aUTMLuY9NCL+OSJWRcS3imdaExEvj4gfRsRdEbEiIl5WrH5W0/u2ryuetiVpFBji0iQTEQcA7wCOycxDgV7gncBMYHlmHgjcDiwqFvky8IHMPARY3dR+HfC5zJxL/ZnWjxTthwHnA68A/oz6U/skjYJJ+9hVaRI7HjgCWFbsJE8HHqP+CtOvFfN8FbixeH/2Lpl5e9F+LfCNiNgJeGlmfgsgM58HKNb3q8xcV4yvBPYGfjb6v5Y0+Rji0uQTwLWZefGAxogPDZpve5/JvKlpuBf/zkijxsPp0uSzFDglIl4EEBG7RcSfUv97cEoxz38EfpaZG4B/i4jXFO3vAm7PzI3Auoj4D8U6pkbEjDH9LSTZQ5Ymm8xcExGXAN+PiArQDZwLPAO8spj2GPXz5gBnAF8oQrr5rV3vAr4YER8t1vG2Mfw1JOFbzCQVIuLpzJxVdh2Shs/D6ZIktSn3xCVJalPuiUuS1KYMcUmS2pQhLklSmzLEJUlqU4a4JEltyhCXJKlN/X+ZVsA81wf2EwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_lc(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSGBd7i9KLTT"
      },
      "source": [
        "## Task 4: Freezing layers in tf.keras\n",
        "\n",
        "You can specify whether the variables from a layer should be updated or not during the training process by setting the layers , trainable attribute. For instance you can see that all the layers from the loaded model have this paremeter set to True if you iterate through them.\n",
        "\n",
        "```\n",
        "for layer in model.layers:\n",
        "  print(layer.trainable)\n",
        "```\n",
        "\n",
        "If you want to freeze them (i.e. not update their weights during training) you can set the parameter to False.\n",
        "\n",
        "```\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "```\n",
        "\n",
        "Try this in the architecture above and see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE51VizFLAaQ"
      },
      "source": [
        "## Task 5: Gradually unfreezing layers\n",
        "\n",
        "For some tasks, the weights learned by the base network are not appropriate enough to constitute a final solution and you might have to update the entire network during training.\n",
        "\n",
        "To avoid training a network that has a highly refined first set of layers and a randomly initialized couple of last layers, a suggested approach is to fine tune the added layers and then gradually unfreeze the layers starting from the top as the training progresses.\n",
        "\n",
        "As a last task you should implement this approach. You can use a smaller pretrained network such as VGG16 or set up a small amount of iterations between each un freezing.\n",
        "\n",
        "You can add these changes directly to Task 3 and check the outcomes."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "757fcd12f07545be93a4e378d7591782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e2ffb143bae490480bb121b4bde8e61",
              "IPY_MODEL_2f4097efd2ba4f5cb56f7e07e1bbd40e",
              "IPY_MODEL_8c151157348348c786d440fc5a462b20"
            ],
            "layout": "IPY_MODEL_7583de7cea9f4ba49dcc5c17fe953109"
          }
        },
        "0e2ffb143bae490480bb121b4bde8e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2d6900a12e4116ae420e7537d6176c",
            "placeholder": "​",
            "style": "IPY_MODEL_9ae2bb70fceb40cb852757d03b0849a9",
            "value": "Dl Completed...: 100%"
          }
        },
        "2f4097efd2ba4f5cb56f7e07e1bbd40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e284d21aca2416cbd3e17627c47a8be",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08da3da300f84d3ca668ec0e1d451c06",
            "value": 5
          }
        },
        "8c151157348348c786d440fc5a462b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c66904a0f9940bea48d0b7bd2d08d7c",
            "placeholder": "​",
            "style": "IPY_MODEL_2d1904b36c8e47f1a5aa5433a9ef6b98",
            "value": " 5/5 [00:02&lt;00:00,  2.36 file/s]"
          }
        },
        "7583de7cea9f4ba49dcc5c17fe953109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2d6900a12e4116ae420e7537d6176c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae2bb70fceb40cb852757d03b0849a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e284d21aca2416cbd3e17627c47a8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08da3da300f84d3ca668ec0e1d451c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c66904a0f9940bea48d0b7bd2d08d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1904b36c8e47f1a5aa5433a9ef6b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}